{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "998a4011",
   "metadata": {},
   "source": [
    "# Imports and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37d4165c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenAI tiktoken module is not available for Python < 3.8,Linux ARM64 and AARCH64. Falling back to GPT2TokenizerFast.\n",
      "WARNING:haystack.nodes.answer_generator.openai:OpenAI tiktoken module is not available for Python < 3.8,Linux ARM64 and AARCH64. Falling back to GPT2TokenizerFast.\n"
     ]
    }
   ],
   "source": [
    "from util import util_elastic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import util_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f911fcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para ter repetibilidade nos resultados\n",
    "random_state = 1\n",
    "\n",
    "# Tratar valores infinitos (+ e -) como np.NaN\n",
    "pd.options.mode.use_inf_as_na = True\n",
    "\n",
    "# IMPORTANTE para tornar figuras interativas\n",
    "# %matplotlib notebook\n",
    "\n",
    "# Tamanho padrão das figuras\n",
    "figsize=(10,6)\n",
    "\n",
    "pd.set_option('display.max_row', 1000)\n",
    "\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "pd.set_option('display.column_space', 40)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "pd.set_option('display.width', 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e05b9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_QUERY = '../data/juris_tcu_index/query.csv'\n",
    "PATH_QREL =  '../data/juris_tcu_index/qrel.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_SEARCH_EXPERIMENT =  '../data/search/juris_tcu_index/search_experiment_juris_tcu_index.csv'\n",
    "PATH_SEARCH_RESULT =  '../data/search/juris_tcu_index/search_experiment_result_juris_tcu_index.csv'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data load"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1cf03f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_query = pd.read_csv(PATH_QUERY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16022, 11)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_query.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a75dd812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>REFERENCE_LIST</th>\n",
       "      <th>PARADIGMATIC</th>\n",
       "      <th>AREA_NAME</th>\n",
       "      <th>AREA_ID_DESCRIPTOR</th>\n",
       "      <th>NORMATIVE_PROCESS_TYPE</th>\n",
       "      <th>NORMATIVE_IDENTIFICATION</th>\n",
       "      <th>NORMATIVE_DATE</th>\n",
       "      <th>NORMATIVE_AUTHOR_TYPE</th>\n",
       "      <th>NORMATIVE_AUTHOR_NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34899</td>\n",
       "      <td>A transferência de documentos da entidade para local impróprio ao armazenamento, causando a perd...</td>\n",
       "      <td>Lei Ordinária 8.443/1992, art. 58, inciso II</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Responsabilidade</td>\n",
       "      <td>775</td>\n",
       "      <td>REPRESENTAÇÃO</td>\n",
       "      <td>Acórdão 2669/2012 - Plenário</td>\n",
       "      <td>2012-10-03</td>\n",
       "      <td>RELATOR</td>\n",
       "      <td>JOSÉ JORGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30271</td>\n",
       "      <td>A contratação de médicos e profissionais da área de saúde, como colaboradores eventuais, com pag...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pessoal</td>\n",
       "      <td>1131</td>\n",
       "      <td>REPRESENTAÇÃO</td>\n",
       "      <td>Acórdão 2669/2012 - Plenário</td>\n",
       "      <td>2012-10-03</td>\n",
       "      <td>RELATOR</td>\n",
       "      <td>JOSÉ JORGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26574</td>\n",
       "      <td>Para que seja conhecido o recurso de revisão, não basta apenas que se apresente documento ainda ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Direito processual</td>\n",
       "      <td>5288</td>\n",
       "      <td>TOMADA DE CONTAS</td>\n",
       "      <td>Acórdão 514/2013 - Plenário</td>\n",
       "      <td>2013-03-13</td>\n",
       "      <td>RELATOR</td>\n",
       "      <td>ANA ARRAES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17902</td>\n",
       "      <td>A contratação de serviços comuns de engenharia que possam ser objetivamente definidos em edital,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Licitação</td>\n",
       "      <td>932</td>\n",
       "      <td>RELATÓRIO DE LEVANTAMENTO</td>\n",
       "      <td>Acórdão 3144/2012 - Plenário</td>\n",
       "      <td>2012-11-21</td>\n",
       "      <td>RELATOR</td>\n",
       "      <td>ANA ARRAES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26089</td>\n",
       "      <td>A Fundação Banco do Brasil, por receber recursos da União, deve observar, quando do repasse de r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Competência do TCU</td>\n",
       "      <td>5095</td>\n",
       "      <td>TOMADA DE CONTAS ESPECIAL</td>\n",
       "      <td>Acórdão 2071/2013 - Plenário</td>\n",
       "      <td>2013-08-07</td>\n",
       "      <td>RELATOR</td>\n",
       "      <td>JOSÉ JORGE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID                                                                                                 TEXT                                REFERENCE_LIST PARADIGMATIC           AREA_NAME  \\\n",
       "0  34899  A transferência de documentos da entidade para local impróprio ao armazenamento, causando a perd...  Lei Ordinária 8.443/1992, art. 58, inciso II          NaN    Responsabilidade   \n",
       "1  30271  A contratação de médicos e profissionais da área de saúde, como colaboradores eventuais, com pag...                                           NaN          NaN             Pessoal   \n",
       "2  26574  Para que seja conhecido o recurso de revisão, não basta apenas que se apresente documento ainda ...                                           NaN          NaN  Direito processual   \n",
       "3  17902  A contratação de serviços comuns de engenharia que possam ser objetivamente definidos em edital,...                                           NaN          NaN           Licitação   \n",
       "4  26089  A Fundação Banco do Brasil, por receber recursos da União, deve observar, quando do repasse de r...                                           NaN          NaN  Competência do TCU   \n",
       "\n",
       "   AREA_ID_DESCRIPTOR     NORMATIVE_PROCESS_TYPE      NORMATIVE_IDENTIFICATION NORMATIVE_DATE NORMATIVE_AUTHOR_TYPE NORMATIVE_AUTHOR_NAME  \n",
       "0                 775              REPRESENTAÇÃO  Acórdão 2669/2012 - Plenário     2012-10-03               RELATOR            JOSÉ JORGE  \n",
       "1                1131              REPRESENTAÇÃO  Acórdão 2669/2012 - Plenário     2012-10-03               RELATOR            JOSÉ JORGE  \n",
       "2                5288           TOMADA DE CONTAS   Acórdão 514/2013 - Plenário     2013-03-13               RELATOR            ANA ARRAES  \n",
       "3                 932  RELATÓRIO DE LEVANTAMENTO  Acórdão 3144/2012 - Plenário     2012-11-21               RELATOR            ANA ARRAES  \n",
       "4                5095  TOMADA DE CONTAS ESPECIAL  Acórdão 2071/2013 - Plenário     2013-08-07               RELATOR            JOSÉ JORGE  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_query.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qrel data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1cf03f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qrel = pd.read_csv(PATH_QREL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94653, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_qrel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a75dd812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_QUERY</th>\n",
       "      <th>ID_DOCTO</th>\n",
       "      <th>TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>158</td>\n",
       "      <td>15147</td>\n",
       "      <td>INDEXACAO_EXTRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>15147</td>\n",
       "      <td>INDEXACAO_EXTRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>178</td>\n",
       "      <td>15147</td>\n",
       "      <td>INDEXACAO_EXTRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14564</td>\n",
       "      <td>15147</td>\n",
       "      <td>INDEXACAO_EXTRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9219</td>\n",
       "      <td>15147</td>\n",
       "      <td>INDEXACAO_EXTRA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_QUERY  ID_DOCTO             TYPE\n",
       "0       158     15147  INDEXACAO_EXTRA\n",
       "1        37     15147  INDEXACAO_EXTRA\n",
       "2       178     15147  INDEXACAO_EXTRA\n",
       "3     14564     15147  INDEXACAO_EXTRA\n",
       "4      9219     15147  INDEXACAO_EXTRA"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_qrel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94653"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_qrel.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_search_data = df_query.merge(df_qrel, how='left', left_on='ID', right_on='ID_QUERY').drop('ID_QUERY', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94653"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_search_data.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupar os dados pelo ID e criar a coluna 'RELEVANCE_LIST' com a lista de tuplas\n",
    "# df_new = df_search_data.groupby('ID').apply(lambda x: list(zip(x['ID_DOCTO'], x['TYPE']))).reset_index(name='RELEVANCE_LIST')\n",
    "# df_new['RELEVANCE_LIST'] = df_new['RELEVANCE_LIST'].apply(lambda x: sorted(x, key=lambda tup: ('AREA', 'TEMA', 'SUBTEMA', 'INDEXACAO_EXTRA').index(tup[1])))\n",
    "df_new = df_search_data.groupby('ID').apply(lambda x: dict(zip(x['ID_DOCTO'], x['TYPE']))).reset_index(name='RELEVANCE_DICT')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>RELEVANCE_DICT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>{1298: 'INDEXACAO_EXTRA', 15340: 'INDEXACAO_EXTRA', 15961: 'INDEXACAO_EXTRA', 1131: 'AREA', 5106...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>{207: 'INDEXACAO_EXTRA', 15961: 'INDEXACAO_EXTRA', 1131: 'AREA', 5106: 'SUBTEMA', 1113: 'TEMA'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>{108: 'INDEXACAO_EXTRA', 1526: 'TEMA', 1727: 'SUBTEMA', 223: 'INDEXACAO_EXTRA', 650: 'INDEXACAO_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>{887: 'SUBTEMA', 92: 'TEMA', 1131: 'AREA', 1100820: 'INDEXACAO_EXTRA'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>{1215: 'INDEXACAO_EXTRA', 14715: 'SUBTEMA', 46: 'TEMA', 1480: 'INDEXACAO_EXTRA', 5095: 'AREA'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                                                                       RELEVANCE_DICT\n",
       "0   5  {1298: 'INDEXACAO_EXTRA', 15340: 'INDEXACAO_EXTRA', 15961: 'INDEXACAO_EXTRA', 1131: 'AREA', 5106...\n",
       "1   6      {207: 'INDEXACAO_EXTRA', 15961: 'INDEXACAO_EXTRA', 1131: 'AREA', 5106: 'SUBTEMA', 1113: 'TEMA'}\n",
       "2   7  {108: 'INDEXACAO_EXTRA', 1526: 'TEMA', 1727: 'SUBTEMA', 223: 'INDEXACAO_EXTRA', 650: 'INDEXACAO_...\n",
       "3   8                               {887: 'SUBTEMA', 92: 'TEMA', 1131: 'AREA', 1100820: 'INDEXACAO_EXTRA'}\n",
       "4   9       {1215: 'INDEXACAO_EXTRA', 14715: 'SUBTEMA', 46: 'TEMA', 1480: 'INDEXACAO_EXTRA', 5095: 'AREA'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unir o resultado com as demais colunas únicas\n",
    "df_new = pd.merge(df_new, df_search_data.drop_duplicates('ID'), on='ID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Selecionar as colunas desejadas\n",
    "df_search_data = df_new[['ID', 'TEXT', 'REFERENCE_LIST', 'PARADIGMATIC', 'AREA_NAME', 'AREA_ID_DESCRIPTOR', 'NORMATIVE_PROCESS_TYPE', 'NORMATIVE_IDENTIFICATION', 'NORMATIVE_DATE', 'NORMATIVE_AUTHOR_TYPE', 'NORMATIVE_AUTHOR_NAME', 'RELEVANCE_DICT']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16022, 12)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_search_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "60e55155",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_search_data = df_search_data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>ID</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>REFERENCE_LIST</th>\n",
       "      <th>PARADIGMATIC</th>\n",
       "      <th>AREA_NAME</th>\n",
       "      <th>AREA_ID_DESCRIPTOR</th>\n",
       "      <th>NORMATIVE_PROCESS_TYPE</th>\n",
       "      <th>NORMATIVE_IDENTIFICATION</th>\n",
       "      <th>NORMATIVE_DATE</th>\n",
       "      <th>NORMATIVE_AUTHOR_TYPE</th>\n",
       "      <th>NORMATIVE_AUTHOR_NAME</th>\n",
       "      <th>RELEVANCE_DICT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>SÚMULA TCU 1: Não se compreendem como vencimento, para efeito de concessão da pensão especial co...</td>\n",
       "      <td>Lei Ordinária 3738/1960 || Lei Ordinária 1711/1952, art. 184</td>\n",
       "      <td>SUMULA</td>\n",
       "      <td>Pessoal</td>\n",
       "      <td>1131</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ata 88/1973 - Plenário</td>\n",
       "      <td>1973-12-04</td>\n",
       "      <td>RELATOR</td>\n",
       "      <td>OCTÁVIO GALLOTTI</td>\n",
       "      <td>{1298: 'INDEXACAO_EXTRA', 15340: 'INDEXACAO_EXTRA', 15961: 'INDEXACAO_EXTRA', 1131: 'AREA', 5106...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>SÚMULA TCU 2: Configura-se como vencimento, para efeito da concessão da pensão especial com fund...</td>\n",
       "      <td>Lei Ordinária 3738/1960</td>\n",
       "      <td>SUMULA</td>\n",
       "      <td>Pessoal</td>\n",
       "      <td>1131</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ata 88/1973 - Plenário</td>\n",
       "      <td>1973-12-04</td>\n",
       "      <td>RELATOR</td>\n",
       "      <td>OCTÁVIO GALLOTTI</td>\n",
       "      <td>{207: 'INDEXACAO_EXTRA', 15961: 'INDEXACAO_EXTRA', 1131: 'AREA', 5106: 'SUBTEMA', 1113: 'TEMA'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>SÚMULA TCU 3: O arquivamento é a solução indicada para as hipóteses em que as contas de responsá...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SUMULA</td>\n",
       "      <td>Direito processual</td>\n",
       "      <td>5288</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ata 88/1973 - Plenário</td>\n",
       "      <td>1973-12-04</td>\n",
       "      <td>RELATOR</td>\n",
       "      <td>OCTÁVIO GALLOTTI</td>\n",
       "      <td>{108: 'INDEXACAO_EXTRA', 1526: 'TEMA', 1727: 'SUBTEMA', 223: 'INDEXACAO_EXTRA', 650: 'INDEXACAO_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>SÚMULA TCU 4: A reclassificação de cargos não aproveita ao servidor aposentado, a menos que lei ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SUMULA</td>\n",
       "      <td>Pessoal</td>\n",
       "      <td>1131</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ata 88/1973 - Plenário</td>\n",
       "      <td>1973-12-04</td>\n",
       "      <td>RELATOR</td>\n",
       "      <td>OCTÁVIO GALLOTTI</td>\n",
       "      <td>{887: 'SUBTEMA', 92: 'TEMA', 1131: 'AREA', 1100820: 'INDEXACAO_EXTRA'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>SÚMULA TCU 5 (REVOGADA): As sociedades de economia mista, salvo disposição expressa em lei, não ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SUMULA</td>\n",
       "      <td>Competência do TCU</td>\n",
       "      <td>5095</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AC 2082/2007-PL</td>\n",
       "      <td>2007-10-03</td>\n",
       "      <td>RELATOR</td>\n",
       "      <td>UBIRATAN AGUIAR</td>\n",
       "      <td>{1215: 'INDEXACAO_EXTRA', 14715: 'SUBTEMA', 46: 'TEMA', 1480: 'INDEXACAO_EXTRA', 5095: 'AREA'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  ID                                                                                                 TEXT                                                REFERENCE_LIST PARADIGMATIC  \\\n",
       "0      0   5  SÚMULA TCU 1: Não se compreendem como vencimento, para efeito de concessão da pensão especial co...  Lei Ordinária 3738/1960 || Lei Ordinária 1711/1952, art. 184       SUMULA   \n",
       "1      1   6  SÚMULA TCU 2: Configura-se como vencimento, para efeito da concessão da pensão especial com fund...                                       Lei Ordinária 3738/1960       SUMULA   \n",
       "2      2   7  SÚMULA TCU 3: O arquivamento é a solução indicada para as hipóteses em que as contas de responsá...                                                           NaN       SUMULA   \n",
       "3      3   8  SÚMULA TCU 4: A reclassificação de cargos não aproveita ao servidor aposentado, a menos que lei ...                                                           NaN       SUMULA   \n",
       "4      4   9  SÚMULA TCU 5 (REVOGADA): As sociedades de economia mista, salvo disposição expressa em lei, não ...                                                           NaN       SUMULA   \n",
       "\n",
       "            AREA_NAME  AREA_ID_DESCRIPTOR NORMATIVE_PROCESS_TYPE NORMATIVE_IDENTIFICATION NORMATIVE_DATE NORMATIVE_AUTHOR_TYPE NORMATIVE_AUTHOR_NAME  \\\n",
       "0             Pessoal                1131                    NaN   Ata 88/1973 - Plenário     1973-12-04               RELATOR      OCTÁVIO GALLOTTI   \n",
       "1             Pessoal                1131                    NaN   Ata 88/1973 - Plenário     1973-12-04               RELATOR      OCTÁVIO GALLOTTI   \n",
       "2  Direito processual                5288                    NaN   Ata 88/1973 - Plenário     1973-12-04               RELATOR      OCTÁVIO GALLOTTI   \n",
       "3             Pessoal                1131                    NaN   Ata 88/1973 - Plenário     1973-12-04               RELATOR      OCTÁVIO GALLOTTI   \n",
       "4  Competência do TCU                5095                    NaN          AC 2082/2007-PL     2007-10-03               RELATOR       UBIRATAN AGUIAR   \n",
       "\n",
       "                                                                                        RELEVANCE_DICT  \n",
       "0  {1298: 'INDEXACAO_EXTRA', 15340: 'INDEXACAO_EXTRA', 15961: 'INDEXACAO_EXTRA', 1131: 'AREA', 5106...  \n",
       "1      {207: 'INDEXACAO_EXTRA', 15961: 'INDEXACAO_EXTRA', 1131: 'AREA', 5106: 'SUBTEMA', 1113: 'TEMA'}  \n",
       "2  {108: 'INDEXACAO_EXTRA', 1526: 'TEMA', 1727: 'SUBTEMA', 223: 'INDEXACAO_EXTRA', 650: 'INDEXACAO_...  \n",
       "3                               {887: 'SUBTEMA', 92: 'TEMA', 1131: 'AREA', 1100820: 'INDEXACAO_EXTRA'}  \n",
       "4       {1215: 'INDEXACAO_EXTRA', 14715: 'SUBTEMA', 46: 'TEMA', 1480: 'INDEXACAO_EXTRA', 5095: 'AREA'}  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_search_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_new"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create reference to index (elastic search)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation https://docs.haystack.deepset.ai/docs\n",
    "https://haystack.deepset.ai/tutorials/09_dpr_training \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: indir_juris_tcu_index\n",
      "{'health': 'yellow', 'status': 'open', 'index': 'indir_juris_tcu_index', 'uuid': 'XqjmOmuaQxqmmxmdE65Q2Q', 'pri': '1', 'rep': '1', 'docs.count': '13252', 'docs.deleted': '13252', 'store.size': '289.2mb', 'pri.store.size': '289.2mb'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "index_dict = util_elastic.return_indexes('indir', parm_print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'indir_juris_tcu_index': {'health': 'yellow',\n",
       "  'status': 'open',\n",
       "  'index': 'indir_juris_tcu_index',\n",
       "  'uuid': 'XqjmOmuaQxqmmxmdE65Q2Q',\n",
       "  'pri': '1',\n",
       "  'rep': '1',\n",
       "  'docs.count': '13252',\n",
       "  'docs.deleted': '13252',\n",
       "  'store.size': '289.2mb',\n",
       "  'pri.store.size': '289.2mb'}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_NAME = 'indir_juris_tcu_index'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Qtd de documentos 13252\n",
      "\n",
      "Qtd de embeddings 13252\n",
      "\n",
      "Documento.id=1: <Document: id=1, content='O termo é \"Abandono de cargo\".\n",
      "Abandono de cargo tem definição: \"Configura abandono de cargo a ausên...'>\n"
     ]
    }
   ],
   "source": [
    "index = util_elastic.return_index(parm_index_name=INDEX_NAME)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test query\n",
    "# parm_query = \"trata-se de uma denúncia contra o prefeito de Manhuaçu por não haver pago os funcionários da área de limpeza urbana\"\n",
    "parm_query = \"A transferência de documentos da entidade para local impróprio ao armazenamento, causando a perda de informações ou inviabilizando seu manuseio, de forma a impedir a atuação do TCU, é causa de responsabilização do gestor que a ordenou.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "nome_modelo_monot5_3b = 'unicamp-dl/mt5-3B-mmarco-en-pt'\n",
    "# \"A mono-ptT5 reranker model (850 mb) pretrained in the BrWac corpus, finetuned for 100k steps on Portuguese translated version of MS MARCO passage dataset. The portuguese dataset was translated using Google Translate.\")\n",
    "nome_caminho_modelo_monot5_3b = \"/home/borela/fontes/relevar-busca/modelo/\" + nome_modelo_monot5_3b\n",
    "assert os.path.exists(nome_caminho_modelo_monot5_3b), f\"Path para {nome_caminho_modelo_monot5_3b} não existe!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "nome_modelo_ranking_minilm = 'unicamp-dl/mMiniLM-L6-v2-pt-v2'\n",
    "nome_caminho_modelo_minilm = \"/home/borela/fontes/relevar-busca/modelo/\" + nome_modelo_ranking_minilm\n",
    "assert os.path.exists(nome_caminho_modelo_minilm), f\"Path para {nome_caminho_modelo_minilm} não existe!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "nome_modelo_embedding_model_sts = \"rufimelo/Legal-BERTimbau-sts-large-ma-v3\"\n",
    "nome_caminho_modelo_sts = \"/home/borela/fontes/relevar-busca/modelo/\" + nome_modelo_embedding_model_sts\n",
    "assert os.path.exists(nome_caminho_modelo_sts), f\"Path para {nome_caminho_modelo_sts} não existe!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Stop execution - create only desired pipelines in code below ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_502418/2302163279.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Stop execution - create only desired pipelines in code below '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mException\u001b[0m: Stop execution - create only desired pipelines in code below "
     ]
    }
   ],
   "source": [
    "raise Exception ('Stop execution - create only desired pipelines in code below ')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First stage = BM25"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pipe_bm25_ranker_monot5_3b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_bm25_ranker_monot5_3b = util_search.return_pipeline_bm25_reranker(index, 'MONOT5', nome_caminho_modelo_monot5_3b, parm_limit_query_size=350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipes.append({'PIPE_NAME': 'pipe_bm25_ranker_monot5_3b',\n",
    "              'PIPE_OBJECT': pipe_bm25_ranker_monot5_3b,\n",
    "              'RETRIEVER_TYPE': 'bm25',  # or 'sts'\n",
    "              'RETRIEVER_MODEL_NAME': '', # or nome_modelo_embedding_model_sts_rufimelo,\n",
    "              'RANKER_MODEL_NAME': nome_modelo_monot5_3b})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parâmetros usados: {}\n",
      "Consulta: A transferência de documentos da entidade para local impróprio ao armazenamento, causando a perda de informações ou inviabilizando seu manuseio, de forma a impedir a atuação do TCU, é causa de responsabilização do gestor que a ordenou.\n",
      "Qtd documentos retornados: 10\n",
      "Primeiro docto:\n",
      "<Document: id=1104189, content='O termo é \"Processo administrativo de responsabilização\". Processo administrativo de responsabilizaç...'>\n",
      "\n",
      "Último (10):\n",
      "<Document: id=1102005, content='O termo é \"Plano de contratações\".\n",
      "Plano de contratações tem definição: \"É o documento no qual a org...'>\n",
      "Seguem os nomes dos termos recuperados em ordem de score\n",
      "0 : ['Processo administrativo de responsabilização', -1.0603076219558716]\n",
      "1 : ['Competência do TCU', -1.4214444160461426]\n",
      "2 : ['Evidência documental', -1.9571717977523804]\n",
      "3 : ['Ofício de requisição', -2.266594648361206]\n",
      "4 : ['Julgamento de contas', -2.5948143005371094]\n",
      "5 : ['Nexo de causalidade', -3.0983963012695312]\n",
      "6 : ['Teletrabalho', -3.176138401031494]\n",
      "7 : ['Papéis de trabalho', -3.9197187423706055]\n",
      "8 : ['Matriz de fiscalização', -4.795485973358154]\n",
      "9 : ['Plano de contratações', -5.823603630065918]\n"
     ]
    }
   ],
   "source": [
    "doctos_retornados_ranker = pipe_bm25_ranker_monot5_3b.run(query=parm_query)\n",
    "util_search.detail_document_found(doctos_retornados_ranker)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pipe_bm25_ranker_minilm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_bm25_ranker_minilm = util_search.return_pipeline_bm25_reranker(index, 'MINILM', nome_caminho_modelo_minilm, parm_limit_query_size=350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipes.append({'PIPE_NAME': 'pipe_bm25_ranker_minilm',\n",
    "              'PIPE_OBJECT': pipe_bm25_ranker_minilm,\n",
    "              'RETRIEVER_TYPE': 'bm25',  # or 'sts'\n",
    "              'RETRIEVER_MODEL_NAME': '', # or nome_modelo_embedding_model_sts_rufimelo,\n",
    "              'RANKER_MODEL_NAME': nome_modelo_ranking_minilm})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parâmetros usados: {}\n",
      "Consulta: A transferência de documentos da entidade para local impróprio ao armazenamento, causando a perda de informações ou inviabilizando seu manuseio, de forma a impedir a atuação do TCU, é causa de responsabilização do gestor que a ordenou.\n",
      "Qtd documentos retornados: 10\n",
      "Primeiro docto:\n",
      "<Document: id=5095, content='O termo é \"Competência do TCU\". Competência do TCU tem definição: \"São as seguintes as competências ...'>\n",
      "\n",
      "Último (10):\n",
      "<Document: id=4495, content='O termo é \"Nexo de causalidade\".\n",
      "Nexo de causalidade tem definição: \"Elemento que evidencia se a con...'>\n",
      "Seguem os nomes dos termos recuperados em ordem de score\n",
      "0 : ['Competência do TCU', 0.0014646538766101003]\n",
      "1 : ['Processo administrativo de responsabilização', 0.0004114470211789012]\n",
      "2 : ['Evidência documental', 0.00033812460605986416]\n",
      "3 : ['Plano de contratações', 0.0002457168884575367]\n",
      "4 : ['Julgamento de contas', 0.00022130725847091526]\n",
      "5 : ['Teletrabalho', 0.00016929447883740067]\n",
      "6 : ['Ofício de requisição', 0.0001542003737995401]\n",
      "7 : ['Papéis de trabalho', 8.805856487015262e-05]\n",
      "8 : ['Matriz de fiscalização', 7.702181028435007e-05]\n",
      "9 : ['Nexo de causalidade', 7.497824117308483e-05]\n"
     ]
    }
   ],
   "source": [
    "doctos_retornados_ranker = pipe_bm25_ranker_minilm.run(query=parm_query)\n",
    "util_search.detail_document_found(doctos_retornados_ranker)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First stage = Sentence Similarity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pipe_sts_ranker_minilm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_sts_ranker_minilm = util_search.return_pipeline_sts_reranker(index, 'MINILM', parm_path_model_ranker=nome_caminho_modelo_minilm, parm_path_model_sts=nome_caminho_modelo_sts, parm_limit_query_size=350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipes.append({'PIPE_NAME': 'pipe_sts_ranker_minilm',\n",
    "              'PIPE_OBJECT': pipe_sts_ranker_minilm,\n",
    "              'RETRIEVER_TYPE': 'sts',  # in ['sts', 'bm25']\n",
    "              'RETRIEVER_MODEL_NAME': nome_modelo_embedding_model_sts, # or nome_modelo_embedding_model_sts_rufimelo,\n",
    "              'RANKER_MODEL_NAME': nome_modelo_ranking_minilm})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parâmetros usados: {}\n",
      "Consulta: A transferência de documentos da entidade para local impróprio ao armazenamento, causando a perda de informações ou inviabilizando seu manuseio, de forma a impedir a atuação do TCU, é causa de responsabilização do gestor que a ordenou.\n",
      "Qtd documentos retornados: 10\n",
      "Primeiro docto:\n",
      "<Document: id=1110487, content='O termo é \"Vazamento de dados\".\n",
      "Vazamento de dados tem definição: \"Transmissão não-autorizada de dad...'>\n",
      "\n",
      "Último (10):\n",
      "<Document: id=15939, content='O termo é \"Erro de procedimento\".\n",
      "Erro de procedimento tem definição: \"É um vício de forma, extrínse...'>\n",
      "Seguem os nomes dos termos recuperados em ordem de score\n",
      "0 : ['Vazamento de dados', 0.0024509401991963387]\n",
      "1 : ['Termo de sigilo', 0.0007997120846994221]\n",
      "2 : ['Trancamento das contas', 0.0002845456183422357]\n",
      "3 : ['Risco de controle', 0.00022979704954195768]\n",
      "4 : ['Revisão de ofício', 0.00013715452223550528]\n",
      "5 : ['Responsabilidade perante o controle externo', 0.00013104191748425364]\n",
      "6 : ['Anulação', 0.00013015586591791362]\n",
      "7 : ['Afastamento de responsável', 0.00012832522043026984]\n",
      "8 : ['Ato vinculado', 8.117296965792775e-05]\n",
      "9 : ['Erro de procedimento', 6.451882654801011e-05]\n"
     ]
    }
   ],
   "source": [
    "doctos_retornados_ranker = pipe_sts_ranker_minilm.run(query=parm_query)\n",
    "util_search.detail_document_found(doctos_retornados_ranker)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pipe_sts_ranker_monot5_3b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_sts_ranker_monot5_3b = util_search.return_pipeline_sts_reranker(index, 'MONOT5', parm_path_model_ranker=nome_caminho_modelo_monot5_3b, parm_path_model_sts=nome_caminho_modelo_sts, parm_limit_query_size=350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipes.append({'PIPE_NAME': 'pipe_sts_ranker_monot5_3b',\n",
    "              'PIPE_OBJECT': pipe_sts_ranker_monot5_3b,\n",
    "              'RETRIEVER_TYPE': 'sts',  # in ['sts', 'bm25']\n",
    "              'RETRIEVER_MODEL_NAME': nome_modelo_embedding_model_sts, # or nome_modelo_embedding_model_sts_rufimelo,\n",
    "              'RANKER_MODEL_NAME': nome_modelo_monot5_3b})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parâmetros usados: {}\n",
      "Consulta: A transferência de documentos da entidade para local impróprio ao armazenamento, causando a perda de informações ou inviabilizando seu manuseio, de forma a impedir a atuação do TCU, é causa de responsabilização do gestor que a ordenou.\n",
      "Qtd documentos retornados: 10\n",
      "Primeiro docto:\n",
      "<Document: id=5098, content='O termo é \"Responsabilidade perante o controle externo\".\n",
      "Responsabilidade perante o controle externo...'>\n",
      "\n",
      "Último (10):\n",
      "<Document: id=83, content='O termo é \"Anulação\". Anulação tem definição: \"É o ato ou a decisão, de caráter judicial ou administ...'>\n",
      "Seguem os nomes dos termos recuperados em ordem de score\n",
      "0 : ['Responsabilidade perante o controle externo', -0.29301929473876953]\n",
      "1 : ['Termo de sigilo', -0.6637465357780457]\n",
      "2 : ['Afastamento de responsável', -0.8156272172927856]\n",
      "3 : ['Revisão de ofício', -0.9923231601715088]\n",
      "4 : ['Trancamento das contas', -1.1499707698822021]\n",
      "5 : ['Erro de procedimento', -2.8979315757751465]\n",
      "6 : ['Vazamento de dados', -2.988812208175659]\n",
      "7 : ['Risco de controle', -3.4774656295776367]\n",
      "8 : ['Ato vinculado', -4.7654876708984375]\n",
      "9 : ['Anulação', -5.362386703491211]\n"
     ]
    }
   ],
   "source": [
    "doctos_retornados_ranker = pipe_sts_ranker_monot5_3b.run(query=parm_query)\n",
    "util_search.detail_document_found(doctos_retornados_ranker)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rodar monoT5_3b: bm25"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### topk_ranker 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'PIPE_NAME': 'pipe_bm25_ranker_monot5_3b',\n",
       "  'PIPE_OBJECT': <haystack.pipelines.base.Pipeline at 0x7fd807582b50>,\n",
       "  'RETRIEVER_TYPE': 'bm25',\n",
       "  'RETRIEVER_MODEL_NAME': '',\n",
       "  'RANKER_MODEL_NAME': 'unicamp-dl/mt5-3B-mmarco-en-pt'}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_experiment = {'CRITERIA' : ['total', 'total_gte_5'],\n",
    "             'TOPK_RETRIEVER' : [300, 200, 100],\n",
    "             'TOPK_RANKER' : [100],\n",
    "             'PIPE': pipes,\n",
    "             'DONE': [False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_experiment = [dict(zip(grid_experiment.keys(), values)) for values in product(*grid_experiment.values())]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(list_experiment))\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_idcg_relevance_fixed {1: 1.0, 2: 1.6309297535714575, 3: 2.1309297535714578, 4: 2.5616063116448506, 5: 2.9484591188793923, 6: 3.3046663059874146, 7: 3.637999639320748, 8: 3.953464516106477, 9: 4.254494511770458, 10: 4.543559338088346, 11: 4.8225022837394755, 12: 5.092740438166795, 13: 5.355389973203989, 14: 5.611347998013804}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'util.util_search' from '/home/borela/fontes/ind-ir/code/util/util_search.py'>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(util_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===0/6===>  2023-Jun-11 19:44:36 experiment: {'CRITERIA': 'total', 'TOPK_RETRIEVER': 300, 'TOPK_RANKER': 100, 'PIPE': {'PIPE_NAME': 'pipe_bm25_ranker_monot5_3b', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7fd807582b50>, 'RETRIEVER_TYPE': 'bm25', 'RETRIEVER_MODEL_NAME': '', 'RANKER_MODEL_NAME': 'unicamp-dl/mt5-3B-mmarco-en-pt'}, 'DONE': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [35:03<00:21, 21.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 4.1\n",
      "NDCG_MEAN: 39.937\n",
      "TIME_SPENT_MEAN: 21.039\n",
      "===1/6===>  2023-Jun-11 20:19:40 experiment: {'CRITERIA': 'total', 'TOPK_RETRIEVER': 200, 'TOPK_RANKER': 100, 'PIPE': {'PIPE_NAME': 'pipe_bm25_ranker_monot5_3b', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7fd807582b50>, 'RETRIEVER_TYPE': 'bm25', 'RETRIEVER_MODEL_NAME': '', 'RANKER_MODEL_NAME': 'unicamp-dl/mt5-3B-mmarco-en-pt'}, 'DONE': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [23:58<00:14, 14.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 3.52\n",
      "NDCG_MEAN: 38.97\n",
      "TIME_SPENT_MEAN: 14.389\n",
      "===2/6===>  2023-Jun-11 20:43:39 experiment: {'CRITERIA': 'total', 'TOPK_RETRIEVER': 100, 'TOPK_RANKER': 100, 'PIPE': {'PIPE_NAME': 'pipe_bm25_ranker_monot5_3b', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7fd807582b50>, 'RETRIEVER_TYPE': 'bm25', 'RETRIEVER_MODEL_NAME': '', 'RANKER_MODEL_NAME': 'unicamp-dl/mt5-3B-mmarco-en-pt'}, 'DONE': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [12:00<00:07,  7.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 2.87\n",
      "NDCG_MEAN: 38.851\n",
      "TIME_SPENT_MEAN: 7.206\n",
      "===3/6===>  2023-Jun-11 20:55:40 experiment: {'CRITERIA': 'total_gte_5', 'TOPK_RETRIEVER': 300, 'TOPK_RANKER': 100, 'PIPE': {'PIPE_NAME': 'pipe_bm25_ranker_monot5_3b', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7fd807582b50>, 'RETRIEVER_TYPE': 'bm25', 'RETRIEVER_MODEL_NAME': '', 'RANKER_MODEL_NAME': 'unicamp-dl/mt5-3B-mmarco-en-pt'}, 'DONE': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [35:48<00:21, 21.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 3.16\n",
      "NDCG_MEAN: 39.915\n",
      "TIME_SPENT_MEAN: 21.487\n",
      "===4/6===>  2023-Jun-11 21:31:28 experiment: {'CRITERIA': 'total_gte_5', 'TOPK_RETRIEVER': 200, 'TOPK_RANKER': 100, 'PIPE': {'PIPE_NAME': 'pipe_bm25_ranker_monot5_3b', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7fd807582b50>, 'RETRIEVER_TYPE': 'bm25', 'RETRIEVER_MODEL_NAME': '', 'RANKER_MODEL_NAME': 'unicamp-dl/mt5-3B-mmarco-en-pt'}, 'DONE': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [24:01<00:14, 14.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 2.81\n",
      "NDCG_MEAN: 40.249\n",
      "TIME_SPENT_MEAN: 14.419\n",
      "===5/6===>  2023-Jun-11 21:55:31 experiment: {'CRITERIA': 'total_gte_5', 'TOPK_RETRIEVER': 100, 'TOPK_RANKER': 100, 'PIPE': {'PIPE_NAME': 'pipe_bm25_ranker_monot5_3b', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7fd807582b50>, 'RETRIEVER_TYPE': 'bm25', 'RETRIEVER_MODEL_NAME': '', 'RANKER_MODEL_NAME': 'unicamp-dl/mt5-3B-mmarco-en-pt'}, 'DONE': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [12:06<00:07,  7.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 2.82\n",
      "NDCG_MEAN: 39.205\n",
      "TIME_SPENT_MEAN: 7.26\n",
      "CPU times: user 1h 26min 8s, sys: 55min 59s, total: 2h 22min 7s\n",
      "Wall time: 2h 23min 1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# colocar pequeno só para testes, depois voltar para 9999999 (número maior do que o número de termos a pesquisar)\n",
    "limit_query = 100 # 9999999\n",
    "for cnt, experiment in enumerate(list_experiment):\n",
    "    if not experiment['DONE']:\n",
    "        list_result_experiment = [] # por experiment\n",
    "        # no caso de normas segecex, bastaria 224 para qtd5 e 891 para qtd1\n",
    "        print(f\"==={cnt}/{len(list_experiment)}===>  {time.strftime('%Y-%b-%d %H:%M:%S')} experiment: {experiment}\")\n",
    "        result_run = util_search.experiment_run(parm_df=df_search_data, \n",
    "                                                parm_experiment=experiment,\n",
    "                                                parm_ndcg_position=12,\n",
    "                                                parm_limit_query=limit_query,\n",
    "                                                parm_print=True)\n",
    "        list_result_experiment.append(result_run)\n",
    "        # print(f\"qtd_encontrado sim:{result_run['qtd_encontrado']}, não:{result_run['qtd_nao_encontrado']} ({result_run['percent_nao_encontrado']}%)\")\n",
    "        experiment['DONE'] = True\n",
    "        util_search.add_experiment_result(parm_list_result=list_result_experiment, \n",
    "                                    parm_path_experiment= PATH_SEARCH_EXPERIMENT,\n",
    "                                    parm_path_experiment_result= PATH_SEARCH_RESULT)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### topk_ranker 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'PIPE_NAME': 'pipe_bm25_ranker_monot5_3b',\n",
       "  'PIPE_OBJECT': <haystack.pipelines.base.Pipeline at 0x7f3ff38305d0>,\n",
       "  'RETRIEVER_TYPE': 'bm25',\n",
       "  'RETRIEVER_MODEL_NAME': '',\n",
       "  'RANKER_MODEL_NAME': 'unicamp-dl/mt5-3B-mmarco-en-pt'}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_experiment = {\n",
    "             'CRITERIA' : ['total', 'total_gte_5'],\n",
    "             'TOPK_RETRIEVER' : [400, 300, 200, 100],\n",
    "             'TOPK_RANKER' : [50],\n",
    "             'DONE': [False],\n",
    "             'PIPE': pipes,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_experiment = [dict(zip(grid_experiment.keys(), values)) for values in product(*grid_experiment.values())]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "114"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(list_experiment))\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_idcg_relevance_fixed {1: 1.0, 2: 1.6309297535714575, 3: 2.1309297535714578, 4: 2.5616063116448506, 5: 2.9484591188793923, 6: 3.3046663059874146, 7: 3.637999639320748, 8: 3.953464516106477, 9: 4.254494511770458, 10: 4.543559338088346, 11: 4.8225022837394755, 12: 5.092740438166795, 13: 5.355389973203989, 14: 5.611347998013804}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'util.util_search' from '/home/borela/fontes/ind-ir/code/util/util_search.py'>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(util_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===0/8===>  2023-Jun-12 11:37:50 experiment: {'CRITERIA': 'total', 'TOPK_RETRIEVER': 400, 'TOPK_RANKER': 50, 'DONE': False, 'PIPE': {'PIPE_NAME': 'pipe_bm25_ranker_monot5_3b', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f3ff38305d0>, 'RETRIEVER_TYPE': 'bm25', 'RETRIEVER_MODEL_NAME': '', 'RANKER_MODEL_NAME': 'unicamp-dl/mt5-3B-mmarco-en-pt'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [46:28<00:28, 28.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 3.57\n",
      "NDCG_MEAN: 39.843\n",
      "TIME_SPENT_MEAN: 27.889\n",
      "===1/8===>  2023-Jun-12 12:24:19 experiment: {'CRITERIA': 'total', 'TOPK_RETRIEVER': 300, 'TOPK_RANKER': 50, 'DONE': False, 'PIPE': {'PIPE_NAME': 'pipe_bm25_ranker_monot5_3b', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f3ff38305d0>, 'RETRIEVER_TYPE': 'bm25', 'RETRIEVER_MODEL_NAME': '', 'RANKER_MODEL_NAME': 'unicamp-dl/mt5-3B-mmarco-en-pt'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [35:27<00:21, 21.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 4.1\n",
      "NDCG_MEAN: 39.937\n",
      "TIME_SPENT_MEAN: 21.274\n",
      "===2/8===>  2023-Jun-12 12:59:47 experiment: {'CRITERIA': 'total', 'TOPK_RETRIEVER': 200, 'TOPK_RANKER': 50, 'DONE': False, 'PIPE': {'PIPE_NAME': 'pipe_bm25_ranker_monot5_3b', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f3ff38305d0>, 'RETRIEVER_TYPE': 'bm25', 'RETRIEVER_MODEL_NAME': '', 'RANKER_MODEL_NAME': 'unicamp-dl/mt5-3B-mmarco-en-pt'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [23:48<00:14, 14.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 3.52\n",
      "NDCG_MEAN: 38.97\n",
      "TIME_SPENT_MEAN: 14.286\n",
      "===3/8===>  2023-Jun-12 13:23:36 experiment: {'CRITERIA': 'total', 'TOPK_RETRIEVER': 100, 'TOPK_RANKER': 50, 'DONE': False, 'PIPE': {'PIPE_NAME': 'pipe_bm25_ranker_monot5_3b', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f3ff38305d0>, 'RETRIEVER_TYPE': 'bm25', 'RETRIEVER_MODEL_NAME': '', 'RANKER_MODEL_NAME': 'unicamp-dl/mt5-3B-mmarco-en-pt'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [11:57<00:07,  7.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 2.87\n",
      "NDCG_MEAN: 38.851\n",
      "TIME_SPENT_MEAN: 7.172\n",
      "===4/8===>  2023-Jun-12 13:35:33 experiment: {'CRITERIA': 'total_gte_5', 'TOPK_RETRIEVER': 400, 'TOPK_RANKER': 50, 'DONE': False, 'PIPE': {'PIPE_NAME': 'pipe_bm25_ranker_monot5_3b', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f3ff38305d0>, 'RETRIEVER_TYPE': 'bm25', 'RETRIEVER_MODEL_NAME': '', 'RANKER_MODEL_NAME': 'unicamp-dl/mt5-3B-mmarco-en-pt'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [47:07<00:28, 28.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 3.6\n",
      "NDCG_MEAN: 39.936\n",
      "TIME_SPENT_MEAN: 28.278\n",
      "===5/8===>  2023-Jun-12 14:22:41 experiment: {'CRITERIA': 'total_gte_5', 'TOPK_RETRIEVER': 300, 'TOPK_RANKER': 50, 'DONE': False, 'PIPE': {'PIPE_NAME': 'pipe_bm25_ranker_monot5_3b', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f3ff38305d0>, 'RETRIEVER_TYPE': 'bm25', 'RETRIEVER_MODEL_NAME': '', 'RANKER_MODEL_NAME': 'unicamp-dl/mt5-3B-mmarco-en-pt'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [35:29<00:21, 21.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 3.16\n",
      "NDCG_MEAN: 39.915\n",
      "TIME_SPENT_MEAN: 21.299\n",
      "===6/8===>  2023-Jun-12 14:58:12 experiment: {'CRITERIA': 'total_gte_5', 'TOPK_RETRIEVER': 200, 'TOPK_RANKER': 50, 'DONE': False, 'PIPE': {'PIPE_NAME': 'pipe_bm25_ranker_monot5_3b', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f3ff38305d0>, 'RETRIEVER_TYPE': 'bm25', 'RETRIEVER_MODEL_NAME': '', 'RANKER_MODEL_NAME': 'unicamp-dl/mt5-3B-mmarco-en-pt'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [23:48<00:14, 14.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 2.81\n",
      "NDCG_MEAN: 40.249\n",
      "TIME_SPENT_MEAN: 14.283\n",
      "===7/8===>  2023-Jun-12 15:22:00 experiment: {'CRITERIA': 'total_gte_5', 'TOPK_RETRIEVER': 100, 'TOPK_RANKER': 50, 'DONE': False, 'PIPE': {'PIPE_NAME': 'pipe_bm25_ranker_monot5_3b', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f3ff38305d0>, 'RETRIEVER_TYPE': 'bm25', 'RETRIEVER_MODEL_NAME': '', 'RANKER_MODEL_NAME': 'unicamp-dl/mt5-3B-mmarco-en-pt'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [11:59<00:07,  7.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 2.82\n",
      "NDCG_MEAN: 39.205\n",
      "TIME_SPENT_MEAN: 7.197\n",
      "CPU times: user 2h 20min 58s, sys: 1h 33min 51s, total: 3h 54min 50s\n",
      "Wall time: 3h 56min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# colocar pequeno só para testes, depois voltar para 9999999 (número maior do que o número de termos a pesquisar)\n",
    "limit_query = 100 # 9999999\n",
    "for cnt, experiment in enumerate(list_experiment):\n",
    "    if not experiment['DONE']:\n",
    "        list_result_experiment = [] # por experiment\n",
    "        # no caso de normas segecex, bastaria 224 para qtd5 e 891 para qtd1\n",
    "        print(f\"==={cnt}/{len(list_experiment)}===>  {time.strftime('%Y-%b-%d %H:%M:%S')} experiment: {experiment}\")\n",
    "        result_run = util_search.experiment_run(parm_df=df_search_data, \n",
    "                                                parm_experiment=experiment,\n",
    "                                                parm_ndcg_position=12,\n",
    "                                                parm_limit_query=limit_query,\n",
    "                                                parm_print=True)\n",
    "        list_result_experiment.append(result_run)\n",
    "        # print(f\"qtd_encontrado sim:{result_run['qtd_encontrado']}, não:{result_run['qtd_nao_encontrado']} ({result_run['percent_nao_encontrado']}%)\")\n",
    "        experiment['DONE'] = True\n",
    "        util_search.add_experiment_result(parm_list_result=list_result_experiment, \n",
    "                                    parm_path_experiment= PATH_SEARCH_EXPERIMENT,\n",
    "                                    parm_path_experiment_result= PATH_SEARCH_RESULT)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rodar mono5-3b:sts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### topk_ranker 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'PIPE_NAME': 'pipe_sts_ranker_monot5_3b',\n",
       "  'PIPE_OBJECT': <haystack.pipelines.base.Pipeline at 0x7f45196091d0>,\n",
       "  'RETRIEVER_TYPE': 'sts',\n",
       "  'RETRIEVER_MODEL_NAME': 'rufimelo/Legal-BERTimbau-sts-large-ma-v3',\n",
       "  'RANKER_MODEL_NAME': 'unicamp-dl/mt5-3B-mmarco-en-pt'}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_experiment = {'CRITERIA' : ['total', 'total_gte_5'],\n",
    "             'TOPK_RETRIEVER' : [300, 200, 100],\n",
    "             'TOPK_RANKER' : [100],\n",
    "             'PIPE': pipes,\n",
    "             'DONE': [False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_experiment = [dict(zip(grid_experiment.keys(), values)) for values in product(*grid_experiment.values())]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(list_experiment))\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_idcg_relevance_fixed {1: 1.0, 2: 1.6309297535714575, 3: 2.1309297535714578, 4: 2.5616063116448506, 5: 2.9484591188793923, 6: 3.3046663059874146, 7: 3.637999639320748, 8: 3.953464516106477, 9: 4.254494511770458, 10: 4.543559338088346, 11: 4.8225022837394755, 12: 5.092740438166795, 13: 5.355389973203989, 14: 5.611347998013804}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'util.util_search' from '/home/borela/fontes/ind-ir/code/util/util_search.py'>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(util_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===0/6===>  2023-Jun-12 07:11:01 experiment: {'CRITERIA': 'total', 'TOPK_RETRIEVER': 300, 'TOPK_RANKER': 100, 'PIPE': {'PIPE_NAME': 'pipe_sts_ranker_monot5_3b', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f45196091d0>, 'RETRIEVER_TYPE': 'sts', 'RETRIEVER_MODEL_NAME': 'rufimelo/Legal-BERTimbau-sts-large-ma-v3', 'RANKER_MODEL_NAME': 'unicamp-dl/mt5-3B-mmarco-en-pt'}, 'DONE': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [33:37<00:20, 20.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 3.81\n",
      "NDCG_MEAN: 36.022\n",
      "TIME_SPENT_MEAN: 20.177\n",
      "===1/6===>  2023-Jun-12 07:44:39 experiment: {'CRITERIA': 'total', 'TOPK_RETRIEVER': 200, 'TOPK_RANKER': 100, 'PIPE': {'PIPE_NAME': 'pipe_sts_ranker_monot5_3b', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f45196091d0>, 'RETRIEVER_TYPE': 'sts', 'RETRIEVER_MODEL_NAME': 'rufimelo/Legal-BERTimbau-sts-large-ma-v3', 'RANKER_MODEL_NAME': 'unicamp-dl/mt5-3B-mmarco-en-pt'}, 'DONE': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [23:00<00:13, 13.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 3.859\n",
      "NDCG_MEAN: 35.575\n",
      "TIME_SPENT_MEAN: 13.801\n",
      "===2/6===>  2023-Jun-12 08:07:39 experiment: {'CRITERIA': 'total', 'TOPK_RETRIEVER': 100, 'TOPK_RANKER': 100, 'PIPE': {'PIPE_NAME': 'pipe_sts_ranker_monot5_3b', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f45196091d0>, 'RETRIEVER_TYPE': 'sts', 'RETRIEVER_MODEL_NAME': 'rufimelo/Legal-BERTimbau-sts-large-ma-v3', 'RANKER_MODEL_NAME': 'unicamp-dl/mt5-3B-mmarco-en-pt'}, 'DONE': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [11:39<00:07,  7.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 3.547\n",
      "NDCG_MEAN: 32.427\n",
      "TIME_SPENT_MEAN: 6.998\n",
      "===3/6===>  2023-Jun-12 08:19:19 experiment: {'CRITERIA': 'total_gte_5', 'TOPK_RETRIEVER': 300, 'TOPK_RANKER': 100, 'PIPE': {'PIPE_NAME': 'pipe_sts_ranker_monot5_3b', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f45196091d0>, 'RETRIEVER_TYPE': 'sts', 'RETRIEVER_MODEL_NAME': 'rufimelo/Legal-BERTimbau-sts-large-ma-v3', 'RANKER_MODEL_NAME': 'unicamp-dl/mt5-3B-mmarco-en-pt'}, 'DONE': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [34:37<00:20, 20.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 3.54\n",
      "NDCG_MEAN: 36.67\n",
      "TIME_SPENT_MEAN: 20.773\n",
      "===4/6===>  2023-Jun-12 08:53:57 experiment: {'CRITERIA': 'total_gte_5', 'TOPK_RETRIEVER': 200, 'TOPK_RANKER': 100, 'PIPE': {'PIPE_NAME': 'pipe_sts_ranker_monot5_3b', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f45196091d0>, 'RETRIEVER_TYPE': 'sts', 'RETRIEVER_MODEL_NAME': 'rufimelo/Legal-BERTimbau-sts-large-ma-v3', 'RANKER_MODEL_NAME': 'unicamp-dl/mt5-3B-mmarco-en-pt'}, 'DONE': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [23:14<00:14, 14.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 3.33\n",
      "NDCG_MEAN: 36.033\n",
      "TIME_SPENT_MEAN: 13.947\n",
      "===5/6===>  2023-Jun-12 09:17:11 experiment: {'CRITERIA': 'total_gte_5', 'TOPK_RETRIEVER': 100, 'TOPK_RANKER': 100, 'PIPE': {'PIPE_NAME': 'pipe_sts_ranker_monot5_3b', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f45196091d0>, 'RETRIEVER_TYPE': 'sts', 'RETRIEVER_MODEL_NAME': 'rufimelo/Legal-BERTimbau-sts-large-ma-v3', 'RANKER_MODEL_NAME': 'unicamp-dl/mt5-3B-mmarco-en-pt'}, 'DONE': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [11:45<00:07,  7.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 2.646\n",
      "NDCG_MEAN: 35.36\n",
      "TIME_SPENT_MEAN: 7.05\n",
      "CPU times: user 1h 19min 45s, sys: 57min 19s, total: 2h 17min 5s\n",
      "Wall time: 2h 17min 55s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# colocar pequeno só para testes, depois voltar para 9999999 (número maior do que o número de termos a pesquisar)\n",
    "limit_query = 100 # 9999999\n",
    "for cnt, experiment in enumerate(list_experiment):\n",
    "    if not experiment['DONE']:\n",
    "        list_result_experiment = [] # por experiment\n",
    "        # no caso de normas segecex, bastaria 224 para qtd5 e 891 para qtd1\n",
    "        print(f\"==={cnt}/{len(list_experiment)}===>  {time.strftime('%Y-%b-%d %H:%M:%S')} experiment: {experiment}\")\n",
    "        result_run = util_search.experiment_run(parm_df=df_search_data, \n",
    "                                                parm_experiment=experiment,\n",
    "                                                parm_ndcg_position=12,\n",
    "                                                parm_limit_query=limit_query,\n",
    "                                                parm_print=True)\n",
    "        list_result_experiment.append(result_run)\n",
    "        # print(f\"qtd_encontrado sim:{result_run['qtd_encontrado']}, não:{result_run['qtd_nao_encontrado']} ({result_run['percent_nao_encontrado']}%)\")\n",
    "        experiment['DONE'] = True\n",
    "        util_search.add_experiment_result(parm_list_result=list_result_experiment, \n",
    "                                    parm_path_experiment= PATH_SEARCH_EXPERIMENT,\n",
    "                                    parm_path_experiment_result= PATH_SEARCH_RESULT)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### topk_ranker 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'PIPE_NAME': 'pipe_sts_ranker_monot5_3b',\n",
       "  'PIPE_OBJECT': <haystack.pipelines.base.Pipeline at 0x7f9037d80290>,\n",
       "  'RETRIEVER_TYPE': 'sts',\n",
       "  'RETRIEVER_MODEL_NAME': 'rufimelo/Legal-BERTimbau-sts-large-ma-v3',\n",
       "  'RANKER_MODEL_NAME': 'unicamp-dl/mt5-3B-mmarco-en-pt'}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_experiment = {\n",
    "             'CRITERIA' : ['total', 'total_gte_5'],\n",
    "             'TOPK_RETRIEVER' : [400, 300, 200, 100],\n",
    "             'TOPK_RANKER' : [50],\n",
    "             'DONE': [False],\n",
    "             'PIPE': pipes,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_experiment = [dict(zip(grid_experiment.keys(), values)) for values in product(*grid_experiment.values())]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(list_experiment))\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_idcg_relevance_fixed {1: 1.0, 2: 1.6309297535714575, 3: 2.1309297535714578, 4: 2.5616063116448506, 5: 2.9484591188793923, 6: 3.3046663059874146, 7: 3.637999639320748, 8: 3.953464516106477, 9: 4.254494511770458, 10: 4.543559338088346, 11: 4.8225022837394755, 12: 5.092740438166795, 13: 5.355389973203989, 14: 5.611347998013804}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'util.util_search' from '/home/borela/fontes/ind-ir/code/util/util_search.py'>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(util_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===0/8===>  2023-Jun-12 17:05:59 experiment: {'CRITERIA': 'total', 'TOPK_RETRIEVER': 400, 'TOPK_RANKER': 50, 'DONE': False, 'PIPE': {'PIPE_NAME': 'pipe_sts_ranker_monot5_3b', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f9037d80290>, 'RETRIEVER_TYPE': 'sts', 'RETRIEVER_MODEL_NAME': 'rufimelo/Legal-BERTimbau-sts-large-ma-v3', 'RANKER_MODEL_NAME': 'unicamp-dl/mt5-3B-mmarco-en-pt'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [44:46<00:27, 27.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 3.87\n",
      "NDCG_MEAN: 36.152\n",
      "TIME_SPENT_MEAN: 26.863\n",
      "===1/8===>  2023-Jun-12 17:50:46 experiment: {'CRITERIA': 'total', 'TOPK_RETRIEVER': 300, 'TOPK_RANKER': 50, 'DONE': False, 'PIPE': {'PIPE_NAME': 'pipe_sts_ranker_monot5_3b', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f9037d80290>, 'RETRIEVER_TYPE': 'sts', 'RETRIEVER_MODEL_NAME': 'rufimelo/Legal-BERTimbau-sts-large-ma-v3', 'RANKER_MODEL_NAME': 'unicamp-dl/mt5-3B-mmarco-en-pt'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [34:07<00:20, 20.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 3.81\n",
      "NDCG_MEAN: 36.022\n",
      "TIME_SPENT_MEAN: 20.474\n",
      "===2/8===>  2023-Jun-12 18:24:53 experiment: {'CRITERIA': 'total', 'TOPK_RETRIEVER': 200, 'TOPK_RANKER': 50, 'DONE': False, 'PIPE': {'PIPE_NAME': 'pipe_sts_ranker_monot5_3b', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f9037d80290>, 'RETRIEVER_TYPE': 'sts', 'RETRIEVER_MODEL_NAME': 'rufimelo/Legal-BERTimbau-sts-large-ma-v3', 'RANKER_MODEL_NAME': 'unicamp-dl/mt5-3B-mmarco-en-pt'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [22:53<00:13, 13.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 3.859\n",
      "NDCG_MEAN: 35.575\n",
      "TIME_SPENT_MEAN: 13.738\n",
      "===3/8===>  2023-Jun-12 18:47:48 experiment: {'CRITERIA': 'total', 'TOPK_RETRIEVER': 100, 'TOPK_RANKER': 50, 'DONE': False, 'PIPE': {'PIPE_NAME': 'pipe_sts_ranker_monot5_3b', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f9037d80290>, 'RETRIEVER_TYPE': 'sts', 'RETRIEVER_MODEL_NAME': 'rufimelo/Legal-BERTimbau-sts-large-ma-v3', 'RANKER_MODEL_NAME': 'unicamp-dl/mt5-3B-mmarco-en-pt'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [11:35<00:07,  7.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 3.547\n",
      "NDCG_MEAN: 32.427\n",
      "TIME_SPENT_MEAN: 6.953\n",
      "===4/8===>  2023-Jun-12 18:59:23 experiment: {'CRITERIA': 'total_gte_5', 'TOPK_RETRIEVER': 400, 'TOPK_RANKER': 50, 'DONE': False, 'PIPE': {'PIPE_NAME': 'pipe_sts_ranker_monot5_3b', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f9037d80290>, 'RETRIEVER_TYPE': 'sts', 'RETRIEVER_MODEL_NAME': 'rufimelo/Legal-BERTimbau-sts-large-ma-v3', 'RANKER_MODEL_NAME': 'unicamp-dl/mt5-3B-mmarco-en-pt'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [45:39<00:27, 27.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 4.25\n",
      "NDCG_MEAN: 35.842\n",
      "TIME_SPENT_MEAN: 27.392\n",
      "===5/8===>  2023-Jun-12 19:45:03 experiment: {'CRITERIA': 'total_gte_5', 'TOPK_RETRIEVER': 300, 'TOPK_RANKER': 50, 'DONE': False, 'PIPE': {'PIPE_NAME': 'pipe_sts_ranker_monot5_3b', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f9037d80290>, 'RETRIEVER_TYPE': 'sts', 'RETRIEVER_MODEL_NAME': 'rufimelo/Legal-BERTimbau-sts-large-ma-v3', 'RANKER_MODEL_NAME': 'unicamp-dl/mt5-3B-mmarco-en-pt'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [34:37<00:20, 20.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 3.54\n",
      "NDCG_MEAN: 36.67\n",
      "TIME_SPENT_MEAN: 20.772\n",
      "===6/8===>  2023-Jun-12 20:19:40 experiment: {'CRITERIA': 'total_gte_5', 'TOPK_RETRIEVER': 200, 'TOPK_RANKER': 50, 'DONE': False, 'PIPE': {'PIPE_NAME': 'pipe_sts_ranker_monot5_3b', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f9037d80290>, 'RETRIEVER_TYPE': 'sts', 'RETRIEVER_MODEL_NAME': 'rufimelo/Legal-BERTimbau-sts-large-ma-v3', 'RANKER_MODEL_NAME': 'unicamp-dl/mt5-3B-mmarco-en-pt'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [23:12<00:14, 14.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 3.33\n",
      "NDCG_MEAN: 36.033\n",
      "TIME_SPENT_MEAN: 13.921\n",
      "===7/8===>  2023-Jun-12 20:42:53 experiment: {'CRITERIA': 'total_gte_5', 'TOPK_RETRIEVER': 100, 'TOPK_RANKER': 50, 'DONE': False, 'PIPE': {'PIPE_NAME': 'pipe_sts_ranker_monot5_3b', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f9037d80290>, 'RETRIEVER_TYPE': 'sts', 'RETRIEVER_MODEL_NAME': 'rufimelo/Legal-BERTimbau-sts-large-ma-v3', 'RANKER_MODEL_NAME': 'unicamp-dl/mt5-3B-mmarco-en-pt'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [11:42<00:07,  7.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 2.646\n",
      "NDCG_MEAN: 35.36\n",
      "TIME_SPENT_MEAN: 7.024\n",
      "CPU times: user 2h 8min 33s, sys: 1h 38min 43s, total: 3h 47min 16s\n",
      "Wall time: 3h 48min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# colocar pequeno só para testes, depois voltar para 9999999 (número maior do que o número de termos a pesquisar)\n",
    "limit_query = 100 # 9999999\n",
    "for cnt, experiment in enumerate(list_experiment):\n",
    "    if not experiment['DONE']:\n",
    "        list_result_experiment = [] # por experiment\n",
    "        # no caso de normas segecex, bastaria 224 para qtd5 e 891 para qtd1\n",
    "        print(f\"==={cnt}/{len(list_experiment)}===>  {time.strftime('%Y-%b-%d %H:%M:%S')} experiment: {experiment}\")\n",
    "        result_run = util_search.experiment_run(parm_df=df_search_data, \n",
    "                                                parm_experiment=experiment,\n",
    "                                                parm_ndcg_position=12,\n",
    "                                                parm_limit_query=limit_query,\n",
    "                                                parm_print=True)\n",
    "        list_result_experiment.append(result_run)\n",
    "        # print(f\"qtd_encontrado sim:{result_run['qtd_encontrado']}, não:{result_run['qtd_nao_encontrado']} ({result_run['percent_nao_encontrado']}%)\")\n",
    "        experiment['DONE'] = True\n",
    "        util_search.add_experiment_result(parm_list_result=list_result_experiment, \n",
    "                                    parm_path_experiment= PATH_SEARCH_EXPERIMENT,\n",
    "                                    parm_path_experiment_result= PATH_SEARCH_RESULT)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rodar minilm: bm25 e sts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'PIPE_NAME': 'pipe_bm25_ranker_minilm',\n",
       "  'PIPE_OBJECT': <haystack.pipelines.base.Pipeline at 0x7f25f350d3d0>,\n",
       "  'RETRIEVER_TYPE': 'bm25',\n",
       "  'RETRIEVER_MODEL_NAME': '',\n",
       "  'RANKER_MODEL_NAME': 'unicamp-dl/mMiniLM-L6-v2-pt-v2'},\n",
       " {'PIPE_NAME': 'pipe_sts_ranker_minilm',\n",
       "  'PIPE_OBJECT': <haystack.pipelines.base.Pipeline at 0x7f25f1badf10>,\n",
       "  'RETRIEVER_TYPE': 'sts',\n",
       "  'RETRIEVER_MODEL_NAME': 'rufimelo/Legal-BERTimbau-sts-large-ma-v3',\n",
       "  'RANKER_MODEL_NAME': 'unicamp-dl/mMiniLM-L6-v2-pt-v2'}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_experiment = {'CRITERIA' : ['total', 'total_gte_5'],\n",
    "             'TOPK_RETRIEVER' : [300, 200, 100],\n",
    "             'TOPK_RANKER' : [100],\n",
    "             'PIPE': pipes,\n",
    "             'DONE': [False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_experiment = [dict(zip(grid_experiment.keys(), values)) for values in product(*grid_experiment.values())]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(list_experiment))\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'util.util_search' from '/home/borela/fontes/ind-ir/code/util/util_search.py'>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(util_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===0/12===>  2023-Jun-12 10:02:16 experiment: {'CRITERIA': 'total', 'TOPK_RETRIEVER': 300, 'TOPK_RANKER': 100, 'PIPE': {'PIPE_NAME': 'pipe_bm25_ranker_minilm', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f25f350d3d0>, 'RETRIEVER_TYPE': 'bm25', 'RETRIEVER_MODEL_NAME': '', 'RANKER_MODEL_NAME': 'unicamp-dl/mMiniLM-L6-v2-pt-v2'}, 'DONE': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [01:20<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 8.626\n",
      "NDCG_MEAN: 24.26\n",
      "TIME_SPENT_MEAN: 0.807\n",
      "===1/12===>  2023-Jun-12 10:03:37 experiment: {'CRITERIA': 'total', 'TOPK_RETRIEVER': 300, 'TOPK_RANKER': 100, 'PIPE': {'PIPE_NAME': 'pipe_sts_ranker_minilm', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f25f1badf10>, 'RETRIEVER_TYPE': 'sts', 'RETRIEVER_MODEL_NAME': 'rufimelo/Legal-BERTimbau-sts-large-ma-v3', 'RANKER_MODEL_NAME': 'unicamp-dl/mMiniLM-L6-v2-pt-v2'}, 'DONE': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [01:20<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 8.505\n",
      "NDCG_MEAN: 22.769\n",
      "TIME_SPENT_MEAN: 0.807\n",
      "===2/12===>  2023-Jun-12 10:04:57 experiment: {'CRITERIA': 'total', 'TOPK_RETRIEVER': 200, 'TOPK_RANKER': 100, 'PIPE': {'PIPE_NAME': 'pipe_bm25_ranker_minilm', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f25f350d3d0>, 'RETRIEVER_TYPE': 'bm25', 'RETRIEVER_MODEL_NAME': '', 'RANKER_MODEL_NAME': 'unicamp-dl/mMiniLM-L6-v2-pt-v2'}, 'DONE': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [00:54<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 8.808\n",
      "NDCG_MEAN: 24.414\n",
      "TIME_SPENT_MEAN: 0.545\n",
      "===3/12===>  2023-Jun-12 10:05:52 experiment: {'CRITERIA': 'total', 'TOPK_RETRIEVER': 200, 'TOPK_RANKER': 100, 'PIPE': {'PIPE_NAME': 'pipe_sts_ranker_minilm', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f25f1badf10>, 'RETRIEVER_TYPE': 'sts', 'RETRIEVER_MODEL_NAME': 'rufimelo/Legal-BERTimbau-sts-large-ma-v3', 'RANKER_MODEL_NAME': 'unicamp-dl/mMiniLM-L6-v2-pt-v2'}, 'DONE': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [00:55<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 8.866\n",
      "NDCG_MEAN: 22.796\n",
      "TIME_SPENT_MEAN: 0.55\n",
      "===4/12===>  2023-Jun-12 10:06:47 experiment: {'CRITERIA': 'total', 'TOPK_RETRIEVER': 100, 'TOPK_RANKER': 100, 'PIPE': {'PIPE_NAME': 'pipe_bm25_ranker_minilm', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f25f350d3d0>, 'RETRIEVER_TYPE': 'bm25', 'RETRIEVER_MODEL_NAME': '', 'RANKER_MODEL_NAME': 'unicamp-dl/mMiniLM-L6-v2-pt-v2'}, 'DONE': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [00:28<00:00,  3.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 8.68\n",
      "NDCG_MEAN: 24.616\n",
      "TIME_SPENT_MEAN: 0.28\n",
      "===5/12===>  2023-Jun-12 10:07:16 experiment: {'CRITERIA': 'total', 'TOPK_RETRIEVER': 100, 'TOPK_RANKER': 100, 'PIPE': {'PIPE_NAME': 'pipe_sts_ranker_minilm', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f25f1badf10>, 'RETRIEVER_TYPE': 'sts', 'RETRIEVER_MODEL_NAME': 'rufimelo/Legal-BERTimbau-sts-large-ma-v3', 'RANKER_MODEL_NAME': 'unicamp-dl/mMiniLM-L6-v2-pt-v2'}, 'DONE': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [00:29<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 8.432\n",
      "NDCG_MEAN: 21.228\n",
      "TIME_SPENT_MEAN: 0.294\n",
      "===6/12===>  2023-Jun-12 10:07:45 experiment: {'CRITERIA': 'total_gte_5', 'TOPK_RETRIEVER': 300, 'TOPK_RANKER': 100, 'PIPE': {'PIPE_NAME': 'pipe_bm25_ranker_minilm', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f25f350d3d0>, 'RETRIEVER_TYPE': 'bm25', 'RETRIEVER_MODEL_NAME': '', 'RANKER_MODEL_NAME': 'unicamp-dl/mMiniLM-L6-v2-pt-v2'}, 'DONE': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [01:21<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 6.33\n",
      "NDCG_MEAN: 24.784\n",
      "TIME_SPENT_MEAN: 0.816\n",
      "===7/12===>  2023-Jun-12 10:09:07 experiment: {'CRITERIA': 'total_gte_5', 'TOPK_RETRIEVER': 300, 'TOPK_RANKER': 100, 'PIPE': {'PIPE_NAME': 'pipe_sts_ranker_minilm', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f25f1badf10>, 'RETRIEVER_TYPE': 'sts', 'RETRIEVER_MODEL_NAME': 'rufimelo/Legal-BERTimbau-sts-large-ma-v3', 'RANKER_MODEL_NAME': 'unicamp-dl/mMiniLM-L6-v2-pt-v2'}, 'DONE': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [01:21<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 7.639\n",
      "NDCG_MEAN: 24.093\n",
      "TIME_SPENT_MEAN: 0.811\n",
      "===8/12===>  2023-Jun-12 10:10:28 experiment: {'CRITERIA': 'total_gte_5', 'TOPK_RETRIEVER': 200, 'TOPK_RANKER': 100, 'PIPE': {'PIPE_NAME': 'pipe_bm25_ranker_minilm', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f25f350d3d0>, 'RETRIEVER_TYPE': 'bm25', 'RETRIEVER_MODEL_NAME': '', 'RANKER_MODEL_NAME': 'unicamp-dl/mMiniLM-L6-v2-pt-v2'}, 'DONE': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [00:54<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 7.58\n",
      "NDCG_MEAN: 24.989\n",
      "TIME_SPENT_MEAN: 0.549\n",
      "===9/12===>  2023-Jun-12 10:11:23 experiment: {'CRITERIA': 'total_gte_5', 'TOPK_RETRIEVER': 200, 'TOPK_RANKER': 100, 'PIPE': {'PIPE_NAME': 'pipe_sts_ranker_minilm', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f25f1badf10>, 'RETRIEVER_TYPE': 'sts', 'RETRIEVER_MODEL_NAME': 'rufimelo/Legal-BERTimbau-sts-large-ma-v3', 'RANKER_MODEL_NAME': 'unicamp-dl/mMiniLM-L6-v2-pt-v2'}, 'DONE': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [00:55<00:00,  1.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 8.475\n",
      "NDCG_MEAN: 23.86\n",
      "TIME_SPENT_MEAN: 0.552\n",
      "===10/12===>  2023-Jun-12 10:12:19 experiment: {'CRITERIA': 'total_gte_5', 'TOPK_RETRIEVER': 100, 'TOPK_RANKER': 100, 'PIPE': {'PIPE_NAME': 'pipe_bm25_ranker_minilm', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f25f350d3d0>, 'RETRIEVER_TYPE': 'bm25', 'RETRIEVER_MODEL_NAME': '', 'RANKER_MODEL_NAME': 'unicamp-dl/mMiniLM-L6-v2-pt-v2'}, 'DONE': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [00:28<00:00,  3.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 7.04\n",
      "NDCG_MEAN: 25.979\n",
      "TIME_SPENT_MEAN: 0.281\n",
      "===11/12===>  2023-Jun-12 10:12:47 experiment: {'CRITERIA': 'total_gte_5', 'TOPK_RETRIEVER': 100, 'TOPK_RANKER': 100, 'PIPE': {'PIPE_NAME': 'pipe_sts_ranker_minilm', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f25f1badf10>, 'RETRIEVER_TYPE': 'sts', 'RETRIEVER_MODEL_NAME': 'rufimelo/Legal-BERTimbau-sts-large-ma-v3', 'RANKER_MODEL_NAME': 'unicamp-dl/mMiniLM-L6-v2-pt-v2'}, 'DONE': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [00:29<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 5.865\n",
      "NDCG_MEAN: 23.582\n",
      "TIME_SPENT_MEAN: 0.29\n",
      "CPU times: user 12min 22s, sys: 3.99 s, total: 12min 26s\n",
      "Wall time: 11min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# colocar pequeno só para testes, depois voltar para 9999999 (número maior do que o número de termos a pesquisar)\n",
    "limit_query = 100 # 9999999\n",
    "for cnt, experiment in enumerate(list_experiment):\n",
    "    if not experiment['DONE']:\n",
    "        list_result_experiment = [] # por experiment\n",
    "        # no caso de normas segecex, bastaria 224 para qtd5 e 891 para qtd1\n",
    "        print(f\"==={cnt}/{len(list_experiment)}===>  {time.strftime('%Y-%b-%d %H:%M:%S')} experiment: {experiment}\")\n",
    "        result_run = util_search.experiment_run(parm_df=df_search_data, \n",
    "                                                parm_experiment=experiment,\n",
    "                                                parm_ndcg_position=12,\n",
    "                                                parm_limit_query=limit_query,\n",
    "                                                parm_print=True)\n",
    "        list_result_experiment.append(result_run)\n",
    "        # print(f\"qtd_encontrado sim:{result_run['qtd_encontrado']}, não:{result_run['qtd_nao_encontrado']} ({result_run['percent_nao_encontrado']}%)\")\n",
    "        experiment['DONE'] = True\n",
    "        util_search.add_experiment_result(parm_list_result=list_result_experiment, \n",
    "                                    parm_path_experiment= PATH_SEARCH_EXPERIMENT,\n",
    "                                    parm_path_experiment_result= PATH_SEARCH_RESULT)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'PIPE_NAME': 'pipe_bm25_ranker_minilm',\n",
       "  'PIPE_OBJECT': <haystack.pipelines.base.Pipeline at 0x7f25f350d3d0>,\n",
       "  'RETRIEVER_TYPE': 'bm25',\n",
       "  'RETRIEVER_MODEL_NAME': '',\n",
       "  'RANKER_MODEL_NAME': 'unicamp-dl/mMiniLM-L6-v2-pt-v2'},\n",
       " {'PIPE_NAME': 'pipe_sts_ranker_minilm',\n",
       "  'PIPE_OBJECT': <haystack.pipelines.base.Pipeline at 0x7f25f1badf10>,\n",
       "  'RETRIEVER_TYPE': 'sts',\n",
       "  'RETRIEVER_MODEL_NAME': 'rufimelo/Legal-BERTimbau-sts-large-ma-v3',\n",
       "  'RANKER_MODEL_NAME': 'unicamp-dl/mMiniLM-L6-v2-pt-v2'}]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_experiment = {'CRITERIA' : ['total', 'total_gte_5'],\n",
    "             'TOPK_RETRIEVER' : [400, 300, 200, 100],\n",
    "             'TOPK_RANKER' : [200, 50],\n",
    "             'PIPE': pipes,\n",
    "             'DONE': [False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_experiment = [dict(zip(grid_experiment.keys(), values)) for values in product(*grid_experiment.values())]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(list_experiment))\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'util.util_search' from '/home/borela/fontes/ind-ir/code/util/util_search.py'>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(util_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===0/32===>  2023-Jun-12 10:13:17 experiment: {'CRITERIA': 'total', 'TOPK_RETRIEVER': 400, 'TOPK_RANKER': 200, 'PIPE': {'PIPE_NAME': 'pipe_bm25_ranker_minilm', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f25f350d3d0>, 'RETRIEVER_TYPE': 'bm25', 'RETRIEVER_MODEL_NAME': '', 'RANKER_MODEL_NAME': 'unicamp-dl/mMiniLM-L6-v2-pt-v2'}, 'DONE': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [01:48<00:01,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 11.13\n",
      "NDCG_MEAN: 24.237\n",
      "TIME_SPENT_MEAN: 1.085\n",
      "===1/32===>  2023-Jun-12 10:15:06 experiment: {'CRITERIA': 'total', 'TOPK_RETRIEVER': 400, 'TOPK_RANKER': 200, 'PIPE': {'PIPE_NAME': 'pipe_sts_ranker_minilm', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f25f1badf10>, 'RETRIEVER_TYPE': 'sts', 'RETRIEVER_MODEL_NAME': 'rufimelo/Legal-BERTimbau-sts-large-ma-v3', 'RANKER_MODEL_NAME': 'unicamp-dl/mMiniLM-L6-v2-pt-v2'}, 'DONE': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [01:47<00:01,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 11.848\n",
      "NDCG_MEAN: 23.229\n",
      "TIME_SPENT_MEAN: 1.075\n",
      "===2/32===>  2023-Jun-12 10:16:53 experiment: {'CRITERIA': 'total', 'TOPK_RETRIEVER': 400, 'TOPK_RANKER': 50, 'PIPE': {'PIPE_NAME': 'pipe_bm25_ranker_minilm', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f25f350d3d0>, 'RETRIEVER_TYPE': 'bm25', 'RETRIEVER_MODEL_NAME': '', 'RANKER_MODEL_NAME': 'unicamp-dl/mMiniLM-L6-v2-pt-v2'}, 'DONE': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [01:47<00:01,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 6.295\n",
      "NDCG_MEAN: 24.237\n",
      "TIME_SPENT_MEAN: 1.076\n",
      "===3/32===>  2023-Jun-12 10:18:41 experiment: {'CRITERIA': 'total', 'TOPK_RETRIEVER': 400, 'TOPK_RANKER': 50, 'PIPE': {'PIPE_NAME': 'pipe_sts_ranker_minilm', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f25f1badf10>, 'RETRIEVER_TYPE': 'sts', 'RETRIEVER_MODEL_NAME': 'rufimelo/Legal-BERTimbau-sts-large-ma-v3', 'RANKER_MODEL_NAME': 'unicamp-dl/mMiniLM-L6-v2-pt-v2'}, 'DONE': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [01:47<00:01,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 5.839\n",
      "NDCG_MEAN: 23.229\n",
      "TIME_SPENT_MEAN: 1.071\n",
      "===4/32===>  2023-Jun-12 10:20:29 experiment: {'CRITERIA': 'total', 'TOPK_RETRIEVER': 300, 'TOPK_RANKER': 200, 'PIPE': {'PIPE_NAME': 'pipe_bm25_ranker_minilm', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f25f350d3d0>, 'RETRIEVER_TYPE': 'bm25', 'RETRIEVER_MODEL_NAME': '', 'RANKER_MODEL_NAME': 'unicamp-dl/mMiniLM-L6-v2-pt-v2'}, 'DONE': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [01:21<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 9.73\n",
      "NDCG_MEAN: 24.26\n",
      "TIME_SPENT_MEAN: 0.815\n",
      "===5/32===>  2023-Jun-12 10:21:50 experiment: {'CRITERIA': 'total', 'TOPK_RETRIEVER': 300, 'TOPK_RANKER': 200, 'PIPE': {'PIPE_NAME': 'pipe_sts_ranker_minilm', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f25f1badf10>, 'RETRIEVER_TYPE': 'sts', 'RETRIEVER_MODEL_NAME': 'rufimelo/Legal-BERTimbau-sts-large-ma-v3', 'RANKER_MODEL_NAME': 'unicamp-dl/mMiniLM-L6-v2-pt-v2'}, 'DONE': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [01:21<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 12.58\n",
      "NDCG_MEAN: 22.769\n",
      "TIME_SPENT_MEAN: 0.815\n",
      "===6/32===>  2023-Jun-12 10:23:12 experiment: {'CRITERIA': 'total', 'TOPK_RETRIEVER': 300, 'TOPK_RANKER': 50, 'PIPE': {'PIPE_NAME': 'pipe_bm25_ranker_minilm', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f25f350d3d0>, 'RETRIEVER_TYPE': 'bm25', 'RETRIEVER_MODEL_NAME': '', 'RANKER_MODEL_NAME': 'unicamp-dl/mMiniLM-L6-v2-pt-v2'}, 'DONE': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [01:21<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 6.396\n",
      "NDCG_MEAN: 24.26\n",
      "TIME_SPENT_MEAN: 0.811\n",
      "===7/32===>  2023-Jun-12 10:24:33 experiment: {'CRITERIA': 'total', 'TOPK_RETRIEVER': 300, 'TOPK_RANKER': 50, 'PIPE': {'PIPE_NAME': 'pipe_sts_ranker_minilm', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f25f1badf10>, 'RETRIEVER_TYPE': 'sts', 'RETRIEVER_MODEL_NAME': 'rufimelo/Legal-BERTimbau-sts-large-ma-v3', 'RANKER_MODEL_NAME': 'unicamp-dl/mMiniLM-L6-v2-pt-v2'}, 'DONE': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [01:20<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 5.699\n",
      "NDCG_MEAN: 22.769\n",
      "TIME_SPENT_MEAN: 0.81\n",
      "===8/32===>  2023-Jun-12 10:25:54 experiment: {'CRITERIA': 'total', 'TOPK_RETRIEVER': 200, 'TOPK_RANKER': 200, 'PIPE': {'PIPE_NAME': 'pipe_bm25_ranker_minilm', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f25f350d3d0>, 'RETRIEVER_TYPE': 'bm25', 'RETRIEVER_MODEL_NAME': '', 'RANKER_MODEL_NAME': 'unicamp-dl/mMiniLM-L6-v2-pt-v2'}, 'DONE': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [00:54<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 9.98\n",
      "NDCG_MEAN: 24.414\n",
      "TIME_SPENT_MEAN: 0.547\n",
      "===9/32===>  2023-Jun-12 10:26:49 experiment: {'CRITERIA': 'total', 'TOPK_RETRIEVER': 200, 'TOPK_RANKER': 200, 'PIPE': {'PIPE_NAME': 'pipe_sts_ranker_minilm', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f25f1badf10>, 'RETRIEVER_TYPE': 'sts', 'RETRIEVER_MODEL_NAME': 'rufimelo/Legal-BERTimbau-sts-large-ma-v3', 'RANKER_MODEL_NAME': 'unicamp-dl/mMiniLM-L6-v2-pt-v2'}, 'DONE': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [00:55<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 11.465\n",
      "NDCG_MEAN: 22.796\n",
      "TIME_SPENT_MEAN: 0.555\n",
      "===10/32===>  2023-Jun-12 10:27:45 experiment: {'CRITERIA': 'total', 'TOPK_RETRIEVER': 200, 'TOPK_RANKER': 50, 'PIPE': {'PIPE_NAME': 'pipe_bm25_ranker_minilm', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f25f350d3d0>, 'RETRIEVER_TYPE': 'bm25', 'RETRIEVER_MODEL_NAME': '', 'RANKER_MODEL_NAME': 'unicamp-dl/mMiniLM-L6-v2-pt-v2'}, 'DONE': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [00:54<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 5.29\n",
      "NDCG_MEAN: 24.414\n",
      "TIME_SPENT_MEAN: 0.545\n",
      "===11/32===>  2023-Jun-12 10:28:40 experiment: {'CRITERIA': 'total', 'TOPK_RETRIEVER': 200, 'TOPK_RANKER': 50, 'PIPE': {'PIPE_NAME': 'pipe_sts_ranker_minilm', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f25f1badf10>, 'RETRIEVER_TYPE': 'sts', 'RETRIEVER_MODEL_NAME': 'rufimelo/Legal-BERTimbau-sts-large-ma-v3', 'RANKER_MODEL_NAME': 'unicamp-dl/mMiniLM-L6-v2-pt-v2'}, 'DONE': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [00:55<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 5.772\n",
      "NDCG_MEAN: 22.796\n",
      "TIME_SPENT_MEAN: 0.55\n",
      "===12/32===>  2023-Jun-12 10:29:35 experiment: {'CRITERIA': 'total', 'TOPK_RETRIEVER': 100, 'TOPK_RANKER': 200, 'PIPE': {'PIPE_NAME': 'pipe_bm25_ranker_minilm', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f25f350d3d0>, 'RETRIEVER_TYPE': 'bm25', 'RETRIEVER_MODEL_NAME': '', 'RANKER_MODEL_NAME': 'unicamp-dl/mMiniLM-L6-v2-pt-v2'}, 'DONE': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [00:27<00:00,  3.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 8.68\n",
      "NDCG_MEAN: 24.616\n",
      "TIME_SPENT_MEAN: 0.279\n",
      "===13/32===>  2023-Jun-12 10:30:03 experiment: {'CRITERIA': 'total', 'TOPK_RETRIEVER': 100, 'TOPK_RANKER': 200, 'PIPE': {'PIPE_NAME': 'pipe_sts_ranker_minilm', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f25f1badf10>, 'RETRIEVER_TYPE': 'sts', 'RETRIEVER_MODEL_NAME': 'rufimelo/Legal-BERTimbau-sts-large-ma-v3', 'RANKER_MODEL_NAME': 'unicamp-dl/mMiniLM-L6-v2-pt-v2'}, 'DONE': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [00:29<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 8.432\n",
      "NDCG_MEAN: 21.228\n",
      "TIME_SPENT_MEAN: 0.291\n",
      "===14/32===>  2023-Jun-12 10:30:33 experiment: {'CRITERIA': 'total', 'TOPK_RETRIEVER': 100, 'TOPK_RANKER': 50, 'PIPE': {'PIPE_NAME': 'pipe_bm25_ranker_minilm', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f25f350d3d0>, 'RETRIEVER_TYPE': 'bm25', 'RETRIEVER_MODEL_NAME': '', 'RANKER_MODEL_NAME': 'unicamp-dl/mMiniLM-L6-v2-pt-v2'}, 'DONE': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [00:27<00:00,  3.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 6.208\n",
      "NDCG_MEAN: 24.616\n",
      "TIME_SPENT_MEAN: 0.278\n",
      "===15/32===>  2023-Jun-12 10:31:01 experiment: {'CRITERIA': 'total', 'TOPK_RETRIEVER': 100, 'TOPK_RANKER': 50, 'PIPE': {'PIPE_NAME': 'pipe_sts_ranker_minilm', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f25f1badf10>, 'RETRIEVER_TYPE': 'sts', 'RETRIEVER_MODEL_NAME': 'rufimelo/Legal-BERTimbau-sts-large-ma-v3', 'RANKER_MODEL_NAME': 'unicamp-dl/mMiniLM-L6-v2-pt-v2'}, 'DONE': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [00:28<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 6.283\n",
      "NDCG_MEAN: 21.228\n",
      "TIME_SPENT_MEAN: 0.289\n",
      "===16/32===>  2023-Jun-12 10:31:30 experiment: {'CRITERIA': 'total_gte_5', 'TOPK_RETRIEVER': 400, 'TOPK_RANKER': 200, 'PIPE': {'PIPE_NAME': 'pipe_bm25_ranker_minilm', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f25f350d3d0>, 'RETRIEVER_TYPE': 'bm25', 'RETRIEVER_MODEL_NAME': '', 'RANKER_MODEL_NAME': 'unicamp-dl/mMiniLM-L6-v2-pt-v2'}, 'DONE': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [01:48<00:01,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 9.79\n",
      "NDCG_MEAN: 24.712\n",
      "TIME_SPENT_MEAN: 1.084\n",
      "===17/32===>  2023-Jun-12 10:33:18 experiment: {'CRITERIA': 'total_gte_5', 'TOPK_RETRIEVER': 400, 'TOPK_RANKER': 200, 'PIPE': {'PIPE_NAME': 'pipe_sts_ranker_minilm', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f25f1badf10>, 'RETRIEVER_TYPE': 'sts', 'RETRIEVER_MODEL_NAME': 'rufimelo/Legal-BERTimbau-sts-large-ma-v3', 'RANKER_MODEL_NAME': 'unicamp-dl/mMiniLM-L6-v2-pt-v2'}, 'DONE': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [01:47<00:01,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 11.182\n",
      "NDCG_MEAN: 23.659\n",
      "TIME_SPENT_MEAN: 1.073\n",
      "===18/32===>  2023-Jun-12 10:35:06 experiment: {'CRITERIA': 'total_gte_5', 'TOPK_RETRIEVER': 400, 'TOPK_RANKER': 50, 'PIPE': {'PIPE_NAME': 'pipe_bm25_ranker_minilm', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f25f350d3d0>, 'RETRIEVER_TYPE': 'bm25', 'RETRIEVER_MODEL_NAME': '', 'RANKER_MODEL_NAME': 'unicamp-dl/mMiniLM-L6-v2-pt-v2'}, 'DONE': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [01:47<00:01,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 5.396\n",
      "NDCG_MEAN: 24.712\n",
      "TIME_SPENT_MEAN: 1.079\n",
      "===19/32===>  2023-Jun-12 10:36:54 experiment: {'CRITERIA': 'total_gte_5', 'TOPK_RETRIEVER': 400, 'TOPK_RANKER': 50, 'PIPE': {'PIPE_NAME': 'pipe_sts_ranker_minilm', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f25f1badf10>, 'RETRIEVER_TYPE': 'sts', 'RETRIEVER_MODEL_NAME': 'rufimelo/Legal-BERTimbau-sts-large-ma-v3', 'RANKER_MODEL_NAME': 'unicamp-dl/mMiniLM-L6-v2-pt-v2'}, 'DONE': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [01:47<00:01,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 5.84\n",
      "NDCG_MEAN: 23.659\n",
      "TIME_SPENT_MEAN: 1.071\n",
      "===20/32===>  2023-Jun-12 10:38:41 experiment: {'CRITERIA': 'total_gte_5', 'TOPK_RETRIEVER': 300, 'TOPK_RANKER': 200, 'PIPE': {'PIPE_NAME': 'pipe_bm25_ranker_minilm', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f25f350d3d0>, 'RETRIEVER_TYPE': 'bm25', 'RETRIEVER_MODEL_NAME': '', 'RANKER_MODEL_NAME': 'unicamp-dl/mMiniLM-L6-v2-pt-v2'}, 'DONE': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [01:21<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 9.38\n",
      "NDCG_MEAN: 24.784\n",
      "TIME_SPENT_MEAN: 0.816\n",
      "===21/32===>  2023-Jun-12 10:40:03 experiment: {'CRITERIA': 'total_gte_5', 'TOPK_RETRIEVER': 300, 'TOPK_RANKER': 200, 'PIPE': {'PIPE_NAME': 'pipe_sts_ranker_minilm', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f25f1badf10>, 'RETRIEVER_TYPE': 'sts', 'RETRIEVER_MODEL_NAME': 'rufimelo/Legal-BERTimbau-sts-large-ma-v3', 'RANKER_MODEL_NAME': 'unicamp-dl/mMiniLM-L6-v2-pt-v2'}, 'DONE': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [01:21<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 11.51\n",
      "NDCG_MEAN: 24.093\n",
      "TIME_SPENT_MEAN: 0.815\n",
      "===22/32===>  2023-Jun-12 10:41:25 experiment: {'CRITERIA': 'total_gte_5', 'TOPK_RETRIEVER': 300, 'TOPK_RANKER': 50, 'PIPE': {'PIPE_NAME': 'pipe_bm25_ranker_minilm', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f25f350d3d0>, 'RETRIEVER_TYPE': 'bm25', 'RETRIEVER_MODEL_NAME': '', 'RANKER_MODEL_NAME': 'unicamp-dl/mMiniLM-L6-v2-pt-v2'}, 'DONE': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [01:21<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 5.615\n",
      "NDCG_MEAN: 24.784\n",
      "TIME_SPENT_MEAN: 0.812\n",
      "===23/32===>  2023-Jun-12 10:42:46 experiment: {'CRITERIA': 'total_gte_5', 'TOPK_RETRIEVER': 300, 'TOPK_RANKER': 50, 'PIPE': {'PIPE_NAME': 'pipe_sts_ranker_minilm', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f25f1badf10>, 'RETRIEVER_TYPE': 'sts', 'RETRIEVER_MODEL_NAME': 'rufimelo/Legal-BERTimbau-sts-large-ma-v3', 'RANKER_MODEL_NAME': 'unicamp-dl/mMiniLM-L6-v2-pt-v2'}, 'DONE': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [01:20<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 4.72\n",
      "NDCG_MEAN: 24.093\n",
      "TIME_SPENT_MEAN: 0.81\n",
      "===24/32===>  2023-Jun-12 10:44:08 experiment: {'CRITERIA': 'total_gte_5', 'TOPK_RETRIEVER': 200, 'TOPK_RANKER': 200, 'PIPE': {'PIPE_NAME': 'pipe_bm25_ranker_minilm', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f25f350d3d0>, 'RETRIEVER_TYPE': 'bm25', 'RETRIEVER_MODEL_NAME': '', 'RANKER_MODEL_NAME': 'unicamp-dl/mMiniLM-L6-v2-pt-v2'}, 'DONE': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [00:55<00:00,  1.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 7.58\n",
      "NDCG_MEAN: 24.989\n",
      "TIME_SPENT_MEAN: 0.553\n",
      "===25/32===>  2023-Jun-12 10:45:03 experiment: {'CRITERIA': 'total_gte_5', 'TOPK_RETRIEVER': 200, 'TOPK_RANKER': 200, 'PIPE': {'PIPE_NAME': 'pipe_sts_ranker_minilm', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f25f1badf10>, 'RETRIEVER_TYPE': 'sts', 'RETRIEVER_MODEL_NAME': 'rufimelo/Legal-BERTimbau-sts-large-ma-v3', 'RANKER_MODEL_NAME': 'unicamp-dl/mMiniLM-L6-v2-pt-v2'}, 'DONE': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [00:55<00:00,  1.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 9.6\n",
      "NDCG_MEAN: 23.86\n",
      "TIME_SPENT_MEAN: 0.555\n",
      "===26/32===>  2023-Jun-12 10:45:59 experiment: {'CRITERIA': 'total_gte_5', 'TOPK_RETRIEVER': 200, 'TOPK_RANKER': 50, 'PIPE': {'PIPE_NAME': 'pipe_bm25_ranker_minilm', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f25f350d3d0>, 'RETRIEVER_TYPE': 'bm25', 'RETRIEVER_MODEL_NAME': '', 'RANKER_MODEL_NAME': 'unicamp-dl/mMiniLM-L6-v2-pt-v2'}, 'DONE': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [00:54<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 4.99\n",
      "NDCG_MEAN: 24.989\n",
      "TIME_SPENT_MEAN: 0.548\n",
      "===27/32===>  2023-Jun-12 10:46:54 experiment: {'CRITERIA': 'total_gte_5', 'TOPK_RETRIEVER': 200, 'TOPK_RANKER': 50, 'PIPE': {'PIPE_NAME': 'pipe_sts_ranker_minilm', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f25f1badf10>, 'RETRIEVER_TYPE': 'sts', 'RETRIEVER_MODEL_NAME': 'rufimelo/Legal-BERTimbau-sts-large-ma-v3', 'RANKER_MODEL_NAME': 'unicamp-dl/mMiniLM-L6-v2-pt-v2'}, 'DONE': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [00:55<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 5.117\n",
      "NDCG_MEAN: 23.86\n",
      "TIME_SPENT_MEAN: 0.551\n",
      "===28/32===>  2023-Jun-12 10:47:49 experiment: {'CRITERIA': 'total_gte_5', 'TOPK_RETRIEVER': 100, 'TOPK_RANKER': 200, 'PIPE': {'PIPE_NAME': 'pipe_bm25_ranker_minilm', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f25f350d3d0>, 'RETRIEVER_TYPE': 'bm25', 'RETRIEVER_MODEL_NAME': '', 'RANKER_MODEL_NAME': 'unicamp-dl/mMiniLM-L6-v2-pt-v2'}, 'DONE': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [00:28<00:00,  3.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 7.04\n",
      "NDCG_MEAN: 25.979\n",
      "TIME_SPENT_MEAN: 0.282\n",
      "===29/32===>  2023-Jun-12 10:48:18 experiment: {'CRITERIA': 'total_gte_5', 'TOPK_RETRIEVER': 100, 'TOPK_RANKER': 200, 'PIPE': {'PIPE_NAME': 'pipe_sts_ranker_minilm', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f25f1badf10>, 'RETRIEVER_TYPE': 'sts', 'RETRIEVER_MODEL_NAME': 'rufimelo/Legal-BERTimbau-sts-large-ma-v3', 'RANKER_MODEL_NAME': 'unicamp-dl/mMiniLM-L6-v2-pt-v2'}, 'DONE': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [00:29<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 5.865\n",
      "NDCG_MEAN: 23.582\n",
      "TIME_SPENT_MEAN: 0.291\n",
      "===30/32===>  2023-Jun-12 10:48:47 experiment: {'CRITERIA': 'total_gte_5', 'TOPK_RETRIEVER': 100, 'TOPK_RANKER': 50, 'PIPE': {'PIPE_NAME': 'pipe_bm25_ranker_minilm', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f25f350d3d0>, 'RETRIEVER_TYPE': 'bm25', 'RETRIEVER_MODEL_NAME': '', 'RANKER_MODEL_NAME': 'unicamp-dl/mMiniLM-L6-v2-pt-v2'}, 'DONE': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [00:27<00:00,  3.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 5.867\n",
      "NDCG_MEAN: 25.979\n",
      "TIME_SPENT_MEAN: 0.279\n",
      "===31/32===>  2023-Jun-12 10:49:15 experiment: {'CRITERIA': 'total_gte_5', 'TOPK_RETRIEVER': 100, 'TOPK_RANKER': 50, 'PIPE': {'PIPE_NAME': 'pipe_sts_ranker_minilm', 'PIPE_OBJECT': <haystack.pipelines.base.Pipeline object at 0x7f25f1badf10>, 'RETRIEVER_TYPE': 'sts', 'RETRIEVER_MODEL_NAME': 'rufimelo/Legal-BERTimbau-sts-large-ma-v3', 'RANKER_MODEL_NAME': 'unicamp-dl/mMiniLM-L6-v2-pt-v2'}, 'DONE': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [00:28<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK1_MEAN: 5.305\n",
      "NDCG_MEAN: 23.582\n",
      "TIME_SPENT_MEAN: 0.289\n",
      "CPU times: user 40min 58s, sys: 10.7 s, total: 41min 9s\n",
      "Wall time: 36min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# colocar pequeno só para testes, depois voltar para 9999999 (número maior do que o número de termos a pesquisar)\n",
    "limit_query = 100 # 9999999\n",
    "for cnt, experiment in enumerate(list_experiment):\n",
    "    if not experiment['DONE']:\n",
    "        list_result_experiment = [] # por experiment\n",
    "        # no caso de normas segecex, bastaria 224 para qtd5 e 891 para qtd1\n",
    "        print(f\"==={cnt}/{len(list_experiment)}===>  {time.strftime('%Y-%b-%d %H:%M:%S')} experiment: {experiment}\")\n",
    "        result_run = util_search.experiment_run(parm_df=df_search_data, \n",
    "                                                parm_experiment=experiment,\n",
    "                                                parm_ndcg_position=12,\n",
    "                                                parm_limit_query=limit_query,\n",
    "                                                parm_print=True)\n",
    "        list_result_experiment.append(result_run)\n",
    "        # print(f\"qtd_encontrado sim:{result_run['qtd_encontrado']}, não:{result_run['qtd_nao_encontrado']} ({result_run['percent_nao_encontrado']}%)\")\n",
    "        experiment['DONE'] = True\n",
    "        util_search.add_experiment_result(parm_list_result=list_result_experiment, \n",
    "                                    parm_path_experiment= PATH_SEARCH_EXPERIMENT,\n",
    "                                    parm_path_experiment_result= PATH_SEARCH_RESULT)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "relevar-busca",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "45978bf3509deeb93161d1472b16f82a40245d44c2beae6c63ad8f9bb3f69171"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
