{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcN_5-RDWeqV"
      },
      "source": [
        "# Finetuning Ranker"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBTqpPgZiC2M"
      },
      "source": [
        "Gratidão ao código base fornecido pelo colega de curso Thiago Soares Laitz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPNvc27A6WFj"
      },
      "source": [
        "# Installs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAoPEGKQpLAN",
        "outputId": "9bc256cc-78d4-43ec-e4e2-f7acb6f9b17c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.39.1)\n"
          ]
        }
      ],
      "source": [
        "pip install bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWn-7w2WstVF",
        "outputId": "4162d91b-5cff-4149-ceba-c4c83c567962"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->accelerate) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "pip install accelerate -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XEO_Or8ul18",
        "outputId": "f25e8f99-357d-4841-a3e9-f1c38d27c3e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n"
          ]
        }
      ],
      "source": [
        "pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umVQVnSBxnKT",
        "outputId": "5e4ac716-1cd8-4add-f5c3-af6ebf69566a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.30.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.65.0)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.9 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.0.1+cu118)\n",
            "Requirement already satisfied: accelerate>=0.20.2 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.20.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.2->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers[torch]) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch!=1.12.0,>=1.9->transformers[torch]) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch!=1.12.0,>=1.9->transformers[torch]) (16.0.6)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.9->transformers[torch]) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.9->transformers[torch]) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers[torch]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lld08iM0uzuL",
        "outputId": "73177e93-3474-4db5-a765-7be3cc374f46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.2.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.15.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhMngMsq6ZIV"
      },
      "source": [
        "# Infra"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNOEKGtZ55uU"
      },
      "source": [
        "## Função de verificação de memória"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2C0W0RMyx2yu"
      },
      "outputs": [],
      "source": [
        "from psutil import virtual_memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ns_pq59lAHke",
        "outputId": "5d90e5fc-a4e7-4f3c-dd73-c0424f6e4d0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Jun 24 16:43:32 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   62C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9XgIWvkkH-kn"
      },
      "outputs": [],
      "source": [
        "def mostra_memoria(lista_mem=['cpu']):\n",
        "  \"\"\"\n",
        "  Esta função exibe informações de memória da CPU e/ou GPU, conforme parâmetros fornecidos.\n",
        "\n",
        "  Parâmetros:\n",
        "  -----------\n",
        "  lista_mem : list, opcional\n",
        "      Lista com strings 'cpu' e/ou 'gpu'.\n",
        "      'cpu' - exibe informações de memória da CPU.\n",
        "      'gpu' - exibe informações de memória da GPU (se disponível).\n",
        "      O valor padrão é ['cpu'].\n",
        "\n",
        "  Saída:\n",
        "  -------\n",
        "  A função não retorna nada, apenas exibe as informações na tela.\n",
        "\n",
        "  Exemplo de uso:\n",
        "  ---------------\n",
        "  Para exibir informações de memória da CPU:\n",
        "      mostra_memoria(['cpu'])\n",
        "\n",
        "  Para exibir informações de memória da CPU e GPU:\n",
        "      mostra_memoria(['cpu', 'gpu'])\n",
        "\n",
        "  Autor: Marcus Vinícius Borela de Castro\n",
        "\n",
        "  \"\"\"\n",
        "  if 'cpu' in lista_mem:\n",
        "    vm = virtual_memory()\n",
        "    ram={}\n",
        "    ram['total']=round(vm.total / 1e9,2)\n",
        "    ram['available']=round(virtual_memory().available / 1e9,2)\n",
        "    # ram['percent']=round(virtual_memory().percent / 1e9,2)\n",
        "    ram['used']=round(virtual_memory().used / 1e9,2)\n",
        "    ram['free']=round(virtual_memory().free / 1e9,2)\n",
        "    ram['active']=round(virtual_memory().active / 1e9,2)\n",
        "    ram['inactive']=round(virtual_memory().inactive / 1e9,2)\n",
        "    ram['buffers']=round(virtual_memory().buffers / 1e9,2)\n",
        "    ram['cached']=round(virtual_memory().cached/1e9 ,2)\n",
        "    print(f\"Your runtime RAM in gb: \\n total {ram['total']}\\n available {ram['available']}\\n used {ram['used']}\\n free {ram['free']}\\n cached {ram['cached']}\\n buffers {ram['buffers']}\")\n",
        "    print('/nGPU')\n",
        "    gpu_info = !nvidia-smi\n",
        "  if 'gpu' in lista_mem:\n",
        "    gpu_info = '\\n'.join(gpu_info)\n",
        "    if gpu_info.find('failed') >= 0:\n",
        "      print('Not connected to a GPU')\n",
        "    else:\n",
        "      print(gpu_info)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dri9iiMAvCT",
        "outputId": "443682f4-5ada-4fdf-f737-850cd5f07857"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime RAM in gb: \n",
            " total 13.61\n",
            " available 12.45\n",
            " used 0.82\n",
            " free 7.01\n",
            " cached 5.72\n",
            " buffers 0.06\n",
            "/nGPU\n",
            "Sat Jun 24 16:43:32 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   62C    P8    12W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "mostra_memoria(['cpu','gpu'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpPSgRGQ5wJv"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGDjEcJ_bawK"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MV8a69JaiEn9"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer\n",
        "import numpy as np\n",
        "import torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TfI-DLjRbTzF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CB1vojvvlt0v"
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass, field"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2b7k0tOuv_L"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZYqAt-NimJH5"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoConfig,\n",
        "    MT5Tokenizer,\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    AutoModelForSequenceClassification,\n",
        "    Trainer,\n",
        "    Seq2SeqTrainer,\n",
        "    Seq2SeqTrainingArguments,\n",
        "    DataCollatorWithPadding,\n",
        "    DataCollatorForSeq2Seq,\n",
        ")\n",
        "from tqdm.auto import tqdm\n",
        "from datasets import Dataset\n",
        "from dataclasses import dataclass, field\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyXTa_7P46Y7"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8v2gtkEPhA0t"
      },
      "source": [
        "## Preparando para debug e display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQ5pmlOHxHhk"
      },
      "outputs": [],
      "source": [
        "def config_display():\n",
        "  \"\"\"\n",
        "  Esta função configura as opções de display do Pandas.\n",
        "  \"\"\"\n",
        "\n",
        "  # Configurando formato saída Pandas\n",
        "  # define o número máximo de colunas que serão exibidas\n",
        "  pd.options.display.max_columns = None\n",
        "\n",
        "  # define a largura máxima de uma linha\n",
        "  pd.options.display.width = 1000\n",
        "\n",
        "  # define o número máximo de linhas que serão exibidas\n",
        "  pd.options.display.max_rows = 100\n",
        "\n",
        "  # define o número máximo de caracteres por coluna\n",
        "  pd.options.display.max_colwidth = 50\n",
        "\n",
        "  # se deve exibir o número de linhas e colunas de um DataFrame.\n",
        "  pd.options.display.show_dimensions = True\n",
        "\n",
        "  # número de dígitos após a vírgula decimal a serem exibidos para floats.\n",
        "  pd.options.display.precision = 7\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2tDy72ATNHs"
      },
      "outputs": [],
      "source": [
        "def config_debug():\n",
        "  \"\"\"\n",
        "  Esta função configura as opções de debug do PyTorch e dos pacotes\n",
        "  transformers e datasets.\n",
        "  \"\"\"\n",
        "\n",
        "  # Define opções de impressão de tensores para o modo científico\n",
        "  torch.set_printoptions(sci_mode=True)\n",
        "  \"\"\"\n",
        "    Significa que valores muito grandes ou muito pequenos são mostrados em notação científica.\n",
        "    Por exemplo, em vez de imprimir o número 0.0000012345 como 0.0000012345,\n",
        "    ele seria impresso como 1.2345e-06. Isso é útil em situações em que os valores dos tensores\n",
        "    envolvidos nas operações são muito grandes ou pequenos, e a notação científica permite\n",
        "    uma melhor compreensão dos números envolvidos.\n",
        "  \"\"\"\n",
        "\n",
        "  # Habilita detecção de anomalias no autograd do PyTorch\n",
        "  torch.autograd.set_detect_anomaly(True)\n",
        "  \"\"\"\n",
        "    Permite identificar operações que podem causar problemas de estabilidade numérica,\n",
        "    como gradientes explodindo ou desaparecendo. Quando essa opção é ativada,\n",
        "    o PyTorch verifica se há operações que geram valores NaN ou infinitos nos tensores\n",
        "    envolvidos no cálculo do gradiente. Se for detectado um valor anômalo, o PyTorch\n",
        "    interrompe a execução e gera uma exceção, permitindo que o erro seja corrigido\n",
        "    antes que se torne um problema maior.\n",
        "\n",
        "    É importante notar que a detecção de anomalias pode ter um impacto significativo\n",
        "    no desempenho, especialmente em modelos grandes e complexos. Por esse motivo,\n",
        "    ela deve ser usada com cautela e apenas para depuração.\n",
        "  \"\"\"\n",
        "\n",
        "  # Configura variável de ambiente para habilitar a execução síncrona (bloqueante) das chamadas da API do CUDA.\n",
        "  os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "  \"\"\"\n",
        "    o Python aguarda o término da execução de uma chamada da API do CUDA antes de executar a próxima chamada.\n",
        "    Isso é útil para depurar erros no código que envolve operações na GPU, pois permite que o erro seja capturado\n",
        "    no momento em que ocorre, e não depois de uma sequência de operações que pode tornar a origem do erro mais difícil de determinar.\n",
        "    No entanto, é importante lembrar que esse modo de execução é significativamente mais lento do que a execução assíncrona,\n",
        "    que é o comportamento padrão do CUDA. Por isso, é recomendado utilizar esse comando apenas em situações de depuração\n",
        "    e removê-lo após a solução do problema.\n",
        "  \"\"\"\n",
        "\n",
        "  # Define o nível de verbosity do pacote transformers para info\n",
        "  # transformers.utils.logging.set_verbosity_info()\n",
        "\n",
        "\n",
        "  \"\"\"\n",
        "    Define o nível de detalhamento das mensagens de log geradas pela biblioteca Hugging Face Transformers\n",
        "    para o nível info. Isso significa que a biblioteca irá imprimir mensagens de log informativas sobre\n",
        "    o andamento da execução, tais como tempo de execução, tamanho de batches, etc.\n",
        "\n",
        "    Essas informações podem ser úteis para entender o que está acontecendo durante a execução da tarefa\n",
        "    e auxiliar no processo de debug. É importante notar que, em alguns casos, a quantidade de informações\n",
        "    geradas pode ser muito grande, o que pode afetar o desempenho do sistema e dificultar a visualização\n",
        "    das informações relevantes. Por isso, é importante ajustar o nível de detalhamento de acordo com a\n",
        "    necessidade de cada tarefa.\n",
        "\n",
        "    Caso queira reduzir a quantidade de mensagens, comentar a linha acima e\n",
        "      descomentar as duas linhas abaixo, para definir o nível de verbosity como error ou warning\n",
        "\n",
        "    transformers.utils.logging.set_verbosity_error()\n",
        "    transformers.utils.logging.set_verbosity_warning()\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  # Define o modo verbose do xmode, que é utilizado no debug\n",
        "  # %xmode Verbose\n",
        "\n",
        "  \"\"\"\n",
        "    Comando usado no Jupyter Notebook para controlar o modo de exibição das informações de exceções.\n",
        "    O modo verbose é um modo detalhado que exibe informações adicionais ao imprimir as exceções.\n",
        "    Ele inclui as informações de pilha de chamadas completa e valores de variáveis locais e globais\n",
        "    no momento da exceção. Isso pode ser útil para depurar e encontrar a causa de exceções em seu código.\n",
        "    Ao usar %xmode Verbose, as informações de exceção serão impressas com mais detalhes e informações adicionais serão incluídas.\n",
        "\n",
        "    Caso queira desabilitar o modo verbose e utilizar o modo plain,\n",
        "    comentar a linha acima e descomentar a linha abaixo:\n",
        "    %xmode Plain\n",
        "  \"\"\"\n",
        "\n",
        "  \"\"\"\n",
        "    Dica:\n",
        "    1.  pdb (Python Debugger)\n",
        "      Quando ocorre uma exceção em uma parte do código, o programa para a execução e exibe uma mensagem de erro\n",
        "      com informações sobre a exceção, como a linha do código em que ocorreu o erro e o tipo da exceção.\n",
        "\n",
        "      Se você estiver depurando o código e quiser examinar o estado das variáveis ​​e executar outras operações\n",
        "      no momento em que a exceção ocorreu, pode usar o pdb (Python Debugger). Para isso, é preciso colocar o comando %debug\n",
        "      logo após ocorrer a exceção. Isso fará com que o programa pare na linha em que ocorreu a exceção e abra o pdb,\n",
        "      permitindo que você explore o estado das variáveis, examine a pilha de chamadas e execute outras operações para depurar o código.\n",
        "\n",
        "\n",
        "    2. ipdb\n",
        "      O ipdb é um depurador interativo para o Python que oferece recursos mais avançados do que o pdb,\n",
        "      incluindo a capacidade de navegar pelo código fonte enquanto depura.\n",
        "\n",
        "      Você pode começar a depurar seu código inserindo o comando ipdb.set_trace() em qualquer lugar do\n",
        "      seu código onde deseja pausar a execução e começar a depurar. Quando a execução chegar nessa linha,\n",
        "      o depurador entrará em ação, permitindo que você examine o estado atual do seu programa e execute\n",
        "      comandos para investigar o comportamento.\n",
        "\n",
        "      Durante a depuração, você pode usar comandos:\n",
        "        next (para executar a próxima linha de código),\n",
        "        step (para entrar em uma função chamada na próxima linha de código)\n",
        "        continue (para continuar a execução normalmente até o próximo ponto de interrupção).\n",
        "\n",
        "      Ao contrário do pdb, o ipdb é um depurador interativo que permite navegar pelo código fonte em que\n",
        "      está trabalhando enquanto depura, permitindo que você inspecione variáveis, defina pontos de interrupção\n",
        "      adicionais e até mesmo execute expressões Python no contexto do seu programa.\n",
        "  \"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tb4aqtcExR84"
      },
      "outputs": [],
      "source": [
        "config_display()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5Bq4043fkfh"
      },
      "outputs": [],
      "source": [
        "config_debug()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9xRdgUGMPgh"
      },
      "source": [
        "## Vinculando pasta do google drive para salvar dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae-Iy2oz_9os",
        "outputId": "b9bdd8ff-8829-41ee-b317-a1c7088e796b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GYGL4MV_yhQ",
        "outputId": "971f5a80-37d5-462c-b6e0-4439d011ca04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current directory: /content\n"
          ]
        }
      ],
      "source": [
        "current_dir = os.getcwd()\n",
        "print(\"Current directory:\", current_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxZrSm-5q77-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPlzXHONq9BC"
      },
      "source": [
        "## Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fEod2-Fjl6fB"
      },
      "outputs": [],
      "source": [
        "TOKEN_FALSE = '▁não'\n",
        "TOKEN_TRUE = '▁sim'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wc5FqYFQrNrE"
      },
      "outputs": [],
      "source": [
        "MODEL_NAME = 'unicamp-dl/ptt5-base-pt-msmarco-100k-v2'\n",
        "# 'unicamp-dl/mt5-3B-mmarco-en-pt'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMrTcbJN55ue"
      },
      "source": [
        "# Carga dos dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hUm-kyDBEHEL"
      },
      "outputs": [],
      "source": [
        "PATH_LOCAL_DATA = '/content/drive/MyDrive/treinamento/202301_IA368DD/indir/data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3KdgJPyrEBzr"
      },
      "outputs": [],
      "source": [
        "# path_data = '/content/drive/MyDrive/treinamento/202301_IA368DD/indir/data/train_data_juris_tcu_index_bm25.csv'\n",
        "\n",
        "PATH_TRAIN_DATA_ZIP = f\"{PATH_LOCAL_DATA}/train_data_juris_tcu_index.zip\"\n",
        "PATH_TRAIN_DATA = f\"{PATH_LOCAL_DATA}/train_data_juris_tcu_index.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrF4PpSvlrcU",
        "outputId": "3b021ced-55b7-4c05-d1b2-95e927cfbd96"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "os.path.exists(PATH_TRAIN_DATA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uFTIlqVHhUR",
        "outputId": "6b456b70-ea11-4996-91c9-48ef6bea533e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File already there!\n",
            "CPU times: user 851 µs, sys: 0 ns, total: 851 µs\n",
            "Wall time: 1.04 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "if not os.path.exists(PATH_TRAIN_DATA):\n",
        "  import zipfile\n",
        "  !wget https://github.com/marcusborela/ind-ir/raw/main/data/train_juris_tcu_index/train_data_juris_tcu_index.csv -O {PATH_TRAIN_DATA}\n",
        "\n",
        "  # Extrair o arquivo zip\n",
        "  with zipfile.ZipFile(PATH_TRAIN_DATA_ZIP, 'r') as zip_ref:\n",
        "      zip_ref.extractall(PATH_LOCAL_DATA)\n",
        "\n",
        "  # Listar os arquivos extraídos\n",
        "  arquivos_extraidos = zip_ref.namelist()\n",
        "  # Exibir os arquivos extraídos\n",
        "  for arquivo in arquivos_extraidos:\n",
        "      print(arquivo)\n",
        "  print(\"File loaded\")\n",
        "else:\n",
        "  print(\"File already there!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0igqAcT55ue"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(PATH_TRAIN_DATA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGRYa-JT55ue",
        "outputId": "edb9b178-a8fa-47d9-89cf-bee615c6011d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(282636, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQ3S90BBTrKJ"
      },
      "source": [
        "Verificando correção do arquivo!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qm7ss2BfTlOu",
        "outputId": "fcc551db-0363-4c28-9983-6ff3b866306b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QUERY_ID          0\n",
            "DOC_ID            0\n",
            "RELEVANCE         0\n",
            "TYPE_RELEVANCE    0\n",
            "DOC_TEXT          0\n",
            "QUERY_TEXT        0\n",
            "Length: 6, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "kxK8j_na55uh",
        "outputId": "5b7374d1-e716-4e9c-a360-8b81aa9d10b3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           QUERY_TEXT        DOC_TEXT\n",
              "count  282636.0000000  282636.0000000\n",
              "mean      314.4387445     971.9820688\n",
              "std       159.8934908     671.0375228\n",
              "min        41.0000000      86.0000000\n",
              "25%       211.0000000     595.0000000\n",
              "50%       286.0000000     812.0000000\n",
              "75%       383.0000000    1162.0000000\n",
              "max      4212.0000000    3739.0000000\n",
              "\n",
              "[8 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-70bdc590-1bee-491a-ac85-d92091a19f7b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>QUERY_TEXT</th>\n",
              "      <th>DOC_TEXT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>282636.0000000</td>\n",
              "      <td>282636.0000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>314.4387445</td>\n",
              "      <td>971.9820688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>159.8934908</td>\n",
              "      <td>671.0375228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>41.0000000</td>\n",
              "      <td>86.0000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>211.0000000</td>\n",
              "      <td>595.0000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>286.0000000</td>\n",
              "      <td>812.0000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>383.0000000</td>\n",
              "      <td>1162.0000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>4212.0000000</td>\n",
              "      <td>3739.0000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-70bdc590-1bee-491a-ac85-d92091a19f7b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-70bdc590-1bee-491a-ac85-d92091a19f7b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-70bdc590-1bee-491a-ac85-d92091a19f7b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "df[['QUERY_TEXT','DOC_TEXT']].applymap(len).describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlXoByaZFIFO"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBvMP8ma55uh"
      },
      "source": [
        "Para cada positivo, tem 2 negativos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bH49RPhY55uh",
        "outputId": "998d38f1-8c3c-4ffd-b089-8dfc24e58403"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    282636.0000000\n",
              "mean          0.3333333\n",
              "std           0.4714054\n",
              "min           0.0000000\n",
              "25%           0.0000000\n",
              "50%           0.0000000\n",
              "75%           1.0000000\n",
              "max           1.0000000\n",
              "Name: RELEVANCE, Length: 8, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "df['RELEVANCE'].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dr1zJQc4-XK"
      },
      "source": [
        "# Treino"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ULDoMS7rkXT"
      },
      "outputs": [],
      "source": [
        "# tokenizer = MT5Tokenizer.from_pretrained(MODEL_NAME)\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-G3PPL_E5_rG"
      },
      "source": [
        "## Data selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrx6whv-DPNY",
        "outputId": "fbbfba1c-3771-4c00-b6bf-ace5c77f243f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(282636, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFOm3DecuTcr"
      },
      "outputs": [],
      "source": [
        "# Se parcial\n",
        "# df2 = df.head(20000)\n",
        "# Se completa\n",
        "df2 = df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2empW1ID1eB"
      },
      "outputs": [],
      "source": [
        "train_examples = {\n",
        "    'query': df2['QUERY_TEXT'].tolist(),\n",
        "    'text': df2['DOC_TEXT'].tolist(),\n",
        "    'label': [TOKEN_FALSE if relevance == 0 else TOKEN_TRUE for relevance in df2['RELEVANCE']]\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cpt7m0jwD3yj"
      },
      "outputs": [],
      "source": [
        "train_examples_count = df2.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BhFjhx0180Wy"
      },
      "outputs": [],
      "source": [
        "del df2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmTGDWSmECHy",
        "outputId": "77950272-9f96-4340-9a0d-c9f348cabc84"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('SÚMULA TCU 1: Não se compreendem como vencimento, para efeito de concessão da pensão especial com fundamento na Lei nº 3.738, de 04/04/60, as vantagens previstas no art. 184 da Lei nº 1.711, de 28/10/52.',\n",
              " 'O termo é \"Pessoal\".\\nPessoal tem nota de escopo: \"Designação genérica de todos os servidores ou funcionários civis pertencentes ao quadro de pessoal de um órgão ou entidade.\".\\nPessoal tem nota de escopo: \"Tema agrupador para área de atuação do Controle Externo.\".\\nPessoal é uma generalização de: \"Servidor público\", \"Funcionário público\", \"Pessoal civil\", \"Pessoal militar\", \"Pessoal temporário\" e \"Colaborador\".\\nPessoal tem termo relacionado: \"Sisac\", \"Despesa com pessoal\" e \"HCAAF\".\\nPessoal tem tradução em espanhol: \"Recursos humanos\".\\nPessoal tem tradução em inglês: \"Personal\" e \"Human resources\".',\n",
              " '▁sim')"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "train_examples['query'][0],train_examples['text'][0], train_examples['label'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFgXJf0zsHuU",
        "outputId": "e86e49ca-a8ba-4f6a-b3dd-3d54f3a61ccd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('SÚMULA TCU 1: Não se compreendem como vencimento, para efeito de concessão da pensão especial com fundamento na Lei nº 3.738, de 04/04/60, as vantagens previstas no art. 184 da Lei nº 1.711, de 28/10/52.',\n",
              " 'O termo é \"Competência do TCU\".\\nCompetência do TCU tem definição: \"São as seguintes as competências atribuídas ao TCU pela Constituição Federal de 1988: Art. 71. O controle externo, a cargo do Congresso Nacional, será exercido com o auxílio do Tribunal de Contas da União, ao qual compete:\\r\\nI - apreciar as contas prestadas anualmente pelo Presidente da República, mediante parecer prévio que deverá ser elaborado em sessenta dias a contar de seu recebimento;\\r\\nII - julgar as contas dos administradores e demais responsáveis por dinheiros, bens e valores públicos da administração direta e indireta, incluídas as fundações e sociedades instituídas e mantidas pelo Poder Público federal, e as contas daqueles que derem causa a perda, extravio ou outra irregularidade de que resulte prejuízo ao erário público;\\r\\nIII - apreciar, para fins de registro, a legalidade dos atos de admissão de pessoal, a qualquer título, na administração direta e indireta, incluídas as fundações instituídas e mantidas pelo Poder Público, excetuadas as nomeações para cargo de provimento em comissão, bem como a das concessões de aposentadorias, reformas e pensões, ressalvadas as melhorias posteriores que não alterem o fundamento legal do ato concessório;\\r\\nIV - realizar, por iniciativa própria, da Câmara dos Deputados, do Senado Federal, de Comissão técnica ou de inquérito, inspeções e auditorias de natureza contábil, financeira, orçamentária, operacional e patrimonial, nas unidades administrativas dos Poderes Legislativo, Executivo e Judiciário, e demais entidades referidas no inciso II;\\r\\nV - fiscalizar as contas nacionais das empresas supranacionais de cujo capital social a União participe, de forma direta ou indireta, nos termos do tratado constitutivo;\\r\\nVI - fiscalizar a aplicação de quaisquer recursos repassados pela União mediante convênio, acordo, ajuste ou outros instrumentos congêneres, a Estado, ao Distrito Federal ou a Município;\\r\\nVII - prestar as informações solicitadas pelo Congresso Nacional, por qualquer de suas Casas, ou por qualquer das respectivas Comissões, sobre a fiscalização contábil, financeira, orçamentária, operacional e patrimonial e sobre resultados de auditorias e inspeções realizadas;\\r\\nVIII - aplicar aos responsáveis, em caso de ilegalidade de despesa ou irregularidade de contas, as sanções previstas em lei, que estabelecerá, entre outras cominações, multa proporcional ao dano causado ao erário;\\r\\nIX - assinar prazo para que o órgão ou entidade adote as providências necessárias ao exato cumprimento da lei, se verificada ilegalidade;\\r\\nX - sustar, se não atendido, a execução do ato impugnado, comunicando a decisão à Câmara dos Deputados e ao Senado Federal;\\r\\nXI - representar ao Poder competente sobre irregularidades ou abusos apurados.\\r\\n§ 1º - No caso de contrato, o ato de sustação será adotado diretamente pelo Congresso Nacional, que solicitará, de imediato, ao Poder Executivo as medidas cabíveis.\\r\\n§ 2º - Se o Congresso Nacional ou o Poder Executivo, no prazo de noventa dias, não efetivar as medidas previstas no parágrafo anterior, o Tribunal decidirá a respeito.\\r\\n§ 3º - As decisões do Tribunal de que resulte imputação de débito ou multa terão eficácia de título executivo.\\r\\n§ 4º - O Tribunal encaminhará ao Congresso Nacional, trimestral e anualmente, relatório de suas atividades.\".\\nCompetência do TCU tem sinônimo: \"Competência do Tribunal de Contas da União\", \"Competências do TCU\" e \"Competências do Tribunal de Contas da União\".\\nCompetência do TCU é uma especialização de: \"Competência\".\\nCompetência do TCU tem termo relacionado: \"Controle de segunda ordem\".\\nCompetência do TCU tem tradução em espanhol: \"Competencia del TCU\".\\nCompetência do TCU tem tradução em inglês: \"TCU Competencies\".',\n",
              " '▁não')"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "train_examples['query'][1],train_examples['text'][1], train_examples['label'][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWY5-2QwD7ey",
        "outputId": "7d265a5b-16ce-4d1e-8b44-116c13a0d145"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "282636\n"
          ]
        }
      ],
      "source": [
        "print(train_examples_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JUJQQuW7bCA"
      },
      "outputs": [],
      "source": [
        "def tokenize(batch):\n",
        "    queries_documents = [f\"Query: {query} Document: {text} Relevant:\" for query, text in zip(batch[\"query\"], batch[\"text\"])]\n",
        "    print(f\"Chamado tokenize len(queries_documents): {len(queries_documents)}\")\n",
        "    tokenized = tokenizer(\n",
        "        queries_documents,\n",
        "        padding=True, # \"max_length\",\n",
        "        truncation=True,\n",
        "        # return_tensors=\"pt\",\n",
        "        max_length= 512\n",
        "    )\n",
        "    # tokenized[\"labels\"] = [[label] for label in batch[\"label\"]]\n",
        "    # tokenized['label'] = [[token_false, token_true][int(pairs[\"label\"][i])]\n",
        "    tokenized[\"labels\"] = tokenizer(batch['label'])['input_ids']\n",
        "    # tokenized[\"labels\"] = [tokenizer.get_vocab()[token] for token in batch['label']]\n",
        "    # tokenized[\"labels\"] = [token_id_true if label == 'true' else token_id_false for label in batch[\"label\"]]\n",
        "    return tokenized\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzmt3FCrE3Xi"
      },
      "outputs": [],
      "source": [
        "train_dataset = Dataset.from_dict(train_examples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0ba3379393564bd0bc348776cc9a0cd0",
            "b361732dc9b448e98a5f73dc5bb81957",
            "8766fc68607d4cef86df608998a71ade",
            "7273542452ea4d3198eaa3a0b5d46831",
            "95f6db9f971c4f7bb0f722ec857215e6",
            "b7b1ef7444fd4e1998ca5909d702529b",
            "cbcf6f23ea864e42acc8e4fb3b133af6",
            "cf4f6fbc03bb4368baae99a7c60e1711",
            "d673fb1c05b9412a819e614f411d4181",
            "e0167f26ed2248b59346c4788d351f56",
            "f3a1ee1f57be4e3d85a1f9720cdb2ac0"
          ]
        },
        "id": "S49luVi-5bFG",
        "outputId": "d03d5ca8-f705-402a-b05d-c3e86bf2e03f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokenizing:   0%|          | 0/282636 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0ba3379393564bd0bc348776cc9a0cd0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 1000\n",
            "Chamado tokenize len(queries_documents): 636\n",
            "CPU times: user 7min 16s, sys: 4.33 s, total: 7min 20s\n",
            "Wall time: 5min 20s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# train_dataset.set_transform(tokenize)\n",
        "train_dataset = train_dataset.map(\n",
        "        tokenize,\n",
        "        remove_columns=('query', 'text', 'label'),\n",
        "        batched=True,\n",
        "        desc='Tokenizing',\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFHMQrDr5XKD",
        "outputId": "8dffb598-0d45-4dd0-a488-4c0dc67c4d5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [2094, 540, 46, 140, 21799, 522, 14604, 89, 299, 165, 746, 10215, 852, 35, 5225, 41, 29, 6434, 6493, 3, 20, 1874, 4, 7170, 11, 18183, 918, 18, 11773, 22, 1090, 19, 31, 23152, 2617, 3, 4, 10837, 113, 2500, 113, 1869, 3, 42, 11563, 7866, 6, 19, 7904, 5, 472, 736, 11, 1090, 19, 18549, 2088, 3, 4, 687, 10392, 113, 4371, 5, 745, 797, 1806, 46, 28, 762, 21, 15, 3181, 1570, 329, 64, 4504, 77, 87, 2649, 4, 19414, 46, 15, 10444, 5219, 778, 21561, 4, 199, 30, 11121, 52, 3461, 4174, 9349, 37, 3155, 4, 1979, 4, 16, 3326, 52, 3593, 5, 64, 4504, 77, 87, 2649, 4, 19414, 46, 15, 2990, 186, 10727, 428, 20, 138, 4, 2704, 10, 15943, 1489, 413, 157, 5, 64, 4504, 77, 21, 17, 1841, 754, 4, 46, 15, 10810, 5574, 33, 534, 49, 15, 17532, 7069, 534, 49, 15, 3181, 1570, 329, 1760, 49, 15, 3181, 1570, 329, 721, 49, 15, 3181, 1570, 329, 15536, 27, 8, 15, 18973, 5800, 428, 64, 4504, 77, 87, 762, 5993, 46, 15, 6500, 6, 2090, 49, 15, 1270, 3037, 277, 18, 1979, 27, 8, 15, 14884, 89, 7354, 64, 4504, 77, 87, 4101, 12, 1830, 46, 15, 1454, 11488, 6, 1855, 64, 4504, 77, 87, 4101, 12, 792, 46, 15, 20444, 77, 27, 8, 15, 7319, 305, 115, 20569, 6, 64, 294, 8985, 5572, 46, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [2593, 1]}\n"
          ]
        }
      ],
      "source": [
        "print(train_dataset[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1d3x4GKr52q",
        "outputId": "b1603a4d-a50b-460a-fb22-c309cb641976"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [2094, 540, 46, 140, 21799, 522, 14604, 89, 299, 165, 746, 10215, 852, 35, 5225, 41, 29, 6434, 6493, 3, 20, 1874, 4, 7170, 11, 18183, 918, 18, 11773, 22, 1090, 19, 31, 23152, 2617, 3, 4, 10837, 113, 2500, 113, 1869, 3, 42, 11563, 7866, 6, 19, 7904, 5, 472, 736, 11, 1090, 19, 18549, 2088, 3, 4, 687, 10392, 113, 4371, 5, 745, 797, 1806, 46, 28, 762, 21, 15, 17664, 629, 1346, 10, 299, 165, 746, 64, 185, 4948, 1346, 10, 299, 165, 746, 87, 3269, 46, 15, 2925, 42, 614, 42, 8215, 6, 6083, 6, 37, 299, 165, 746, 50, 2854, 836, 4, 3887, 46, 3797, 5, 9510, 5, 28, 898, 8927, 3, 7, 758, 10, 2137, 381, 3, 1133, 15243, 18, 9, 7893, 10, 2330, 4, 3908, 6, 11, 842, 3, 37, 184, 8008, 46, 116, 78, 8187, 33, 42, 12558, 6469, 178, 4664, 54, 1562, 11, 651, 3, 6854, 9158, 19445, 13, 10166, 57, 9257, 12, 11566, 444, 7, 5065, 4, 45, 22771, 74, 500, 78, 18320, 42, 12558, 34, 20533, 8, 1809, 3996, 26, 1708, 6, 3, 3870, 8, 2123, 3205, 11, 1822, 3614, 8, 17004, 3, 12095, 42, 18692, 8, 10365, 16366, 6, 8, 7205, 6, 54, 7090, 4235, 1710, 3, 8, 42, 12558, 13272, 13, 4, 802, 698, 7, 2171, 3, 2251, 3215, 52, 584, 10229, 441, 4, 13, 115, 5250, 146, 11549, 37, 8, 33, 1073, 534, 74, 1271, 78, 8187, 33, 3, 20, 3346, 4, 3704, 3, 7, 3650, 441, 34, 6513, 4, 18835, 4, 1979, 3, 7, 510, 340, 3, 22, 1822, 3614, 8, 17004, 3, 12095, 42, 18692, 16366, 6, 8, 7205, 6, 54, 7090, 4235, 3, 239, 238, 672, 1026, 42, 19126, 20, 758, 4, 615, 405, 426, 12, 4594, 3, 219, 29, 7, 51, 17770, 4, 9350, 6, 3, 6108, 8, 1359, 18386, 3, 115, 1036, 8878, 178, 42, 11208, 4842, 13, 47, 956, 413, 131, 9, 11773, 3650, 10, 4780, 9009, 6, 6, 9714, 74, 1938, 78, 1850, 3, 26, 3985, 812, 3, 11, 1221, 34, 7504, 3, 10, 3449, 836, 3, 4, 2284, 1977, 52, 4, 14832, 3, 164, 3037, 229, 8, 19157, 2439, 4, 1603, 602, 1442, 2653, 3, 5145, 3, 9, 33, 751, 1806, 1885, 3, 6120, 8, 4750, 331, 16333, 77, 3, 117, 1621, 713, 6, 34, 7090, 79, 13947, 3, 9269, 8, 18402, 3, 8, 1809, 6391, 6267, 6, 19, 5538, 133, 43, 500, 74, 475, 78, 22496, 33, 42, 12558, 2165, 51, 1229, 15539, 102, 3951, 4, 1560, 546, 789, 7, 842, 6843, 485, 390, 3, 4, 156, 3614, 52, 17004, 3, 84, 1416, 10, 3296, 31, 7398, 1091, 74, 2806, 78, 22496, 33, 7, 3372, 4, 8509, 1572, 115, 10703, 154, 50, 842, 6854, 20538, 3, 237, 3, 16630, 52, 129, 3487, 602, 14838, 192, 379, 3, 7, 380, 3, 37, 2183, 836, 52, 7, 5634, 74, 5247, 78, 12480, 42, 1614, 6703, 178, 54, 2137, 381, 3, 26, 510, 4, 125, 908, 6, 3, 52, 26, 510, 51, 12403, 531, 8739, 3, 81, 7, 18522, 602, 1442, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [47, 1]}\n"
          ]
        }
      ],
      "source": [
        "print(train_dataset[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hig02oOb580I"
      },
      "source": [
        "## setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxFMX-y4ZkLF",
        "outputId": "60f3b841-71ce-41c6-adaa-858cf3c131ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  gdrive  sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PrkV4fIUI22Z"
      },
      "outputs": [],
      "source": [
        " PATH_TRAIN_MODEL_LOCAL = \"/content/drive/MyDrive/treinamento/202301_IA368DD/indir/train/monot5\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bGJOtzX4FhnF"
      },
      "outputs": [],
      "source": [
        "training_args = Seq2SeqTrainingArguments(output_dir=PATH_TRAIN_MODEL_LOCAL)\n",
        "# Needed to make the Trainer work with an on-the-fly transformation on the dataset\n",
        "# training_args.remove_unused_columns = False\n",
        "training_args.output_dir = PATH_TRAIN_MODEL_LOCAL\n",
        "training_args.warmup_steps=200 # Alterar!\n",
        "training_args.num_train_epochs=1.0 # Alterar!\n",
        "training_args.logging_steps=200 # Alterar!\n",
        "training_args.save_strategy=\"steps\"\n",
        "training_args.save_steps=200\n",
        "training_args.save_total_limit=4\n",
        "training_args.learning_rate=5e-5\n",
        "training_args.per_device_train_batch_size=8 # Alterar!\n",
        "training_args.gradient_accumulation_steps=4 # Alterar!\n",
        "#training_args._n_gpu = 1\n",
        "training_args.bf16 = True # se for usar a100, 3090, 4090 -> usar\n",
        "training_args.evaluation_strategy = \"no\"\n",
        "training_args.ignore_data_skip = True\n",
        "training_args.do_eval = False\n",
        "training_args.load_best_model_at_end = True\n",
        "# training_args.optim='adamw_hf' #default\n",
        "training_args.gradient_checkpointing = False # True\n",
        "# se precisar economizar gpu\n",
        "# training_args.optim='adamw_bnb_8bit'\n",
        "# training_args.gradient_checkpointing = True\n",
        "# training_args.report_to=\"none\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mMQw6ra63Xk",
        "outputId": "3ad4b3be-ca6f-4e25-cca4-93a6ed8fb563"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seq2SeqTrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=True,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_backend=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=False,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=None,\n",
            "evaluation_strategy=no,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "generation_config=None,\n",
            "generation_max_length=None,\n",
            "generation_num_beams=None,\n",
            "gradient_accumulation_steps=4,\n",
            "gradient_checkpointing=False,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=True,\n",
            "include_inputs_for_metrics=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=5e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=/content/drive/MyDrive/treinamento/202301_IA368DD/indir/train/monot5/runs/Jun24_16-49-26_3e53463982a9,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=200,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=1.0,\n",
            "optim=adamw_hf,\n",
            "optim_args=None,\n",
            "output_dir=/content/drive/MyDrive/treinamento/202301_IA368DD/indir/train/monot5,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=8,\n",
            "predict_with_generate=False,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=/content/drive/MyDrive/treinamento/202301_IA368DD/indir/train/monot5,\n",
            "save_on_each_node=False,\n",
            "save_safetensors=False,\n",
            "save_steps=200,\n",
            "save_strategy=steps,\n",
            "save_total_limit=4,\n",
            "seed=42,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "sortish_sampler=False,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=200,\n",
            "weight_decay=0.0,\n",
            "xpu_backend=None,\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(training_args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nBRTbzhSW7hF"
      },
      "outputs": [],
      "source": [
        "# from transformers.integrations import NeptuneCallback\n",
        "# rastro_neptune = NeptuneRastroRun(hparam, parm_lista_tag= tag_contexto_rastro)\n",
        "# neptune_callback = NeptuneCallback(run=rastro_neptune)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJt67cC8u7XO",
        "outputId": "d32d8560-7538-451e-b0fb-45f0520c37d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2.8 s, sys: 1.19 s, total: 4 s\n",
            "Wall time: 7.3 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrK0NBIV2GjX"
      },
      "outputs": [],
      "source": [
        "trainer_cls = Seq2SeqTrainer\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Srq3KA_ZlWPD"
      },
      "outputs": [],
      "source": [
        "# Limpa o cache da memória da GPU\n",
        "# del trainer\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoik0K8sX3Jg"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "XhSrqbj-tgFm",
        "outputId": "a3eb242d-958f-4237-90b8-594d1cc7e588"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
              "\u001b[31m│\u001b[0m in \u001b[92m<cell line: 1>\u001b[0m:\u001b[94m1\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
              "\u001b[1;91mException: \u001b[0mParar aqui reinício!\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 1&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">Exception: </span>Parar aqui reinício!\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "raise Exception('Parar aqui reinício!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jqrhQxd3E55t"
      },
      "outputs": [],
      "source": [
        "trainer = trainer_cls(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "train_metrics = trainer.train(resume_from_checkpoint=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6DDvR-7xS_7_",
        "outputId": "9f134523-645c-4903-c0b4-8a87bf63da5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7752' max='8832' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7752/8832 17:40:17 < 3:00:20, 0.10 it/s, Epoch 0.72/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.164600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.149500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.147500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.139800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.145200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.140400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.138300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.157000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.153800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.153500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.144900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.144500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.148000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.138700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>0.145100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>0.133900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>0.138100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.140400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>0.137400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>0.140900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>0.135300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>0.134600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.138700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6200</td>\n",
              "      <td>0.134300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6400</td>\n",
              "      <td>0.135300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6600</td>\n",
              "      <td>0.124800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6800</td>\n",
              "      <td>0.133300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.135700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7200</td>\n",
              "      <td>0.126100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7400</td>\n",
              "      <td>0.137100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7600</td>\n",
              "      <td>0.124300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7883' max='8832' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7883/8832 18:02:28 < 2:38:30, 0.10 it/s, Epoch 0.73/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.164600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.149500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.147500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.139800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.145200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.140400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.138300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.157000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.153800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.153500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.144900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.144500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.148000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.138700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>0.145100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>0.133900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>0.138100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.140400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>0.137400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>0.140900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>0.135300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>0.134600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.138700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6200</td>\n",
              "      <td>0.134300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6400</td>\n",
              "      <td>0.135300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6600</td>\n",
              "      <td>0.124800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6800</td>\n",
              "      <td>0.133300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.135700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7200</td>\n",
              "      <td>0.126100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7400</td>\n",
              "      <td>0.137100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7600</td>\n",
              "      <td>0.124300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7800</td>\n",
              "      <td>0.125600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raise Exception('Parar aqui reinício!')"
      ],
      "metadata": {
        "id": "YPiW-idbTBT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vk45mDpFTBQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-7jcR6UGTBND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f52oOat4TBJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G11io7h6ncEu"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "train_metrics = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "E7FkDpLfIiu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "train_metrics = trainer.train(resume_from_checkpoint=True)"
      ],
      "metadata": {
        "id": "iumeAAiZSWRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "antigos"
      ],
      "metadata": {
        "id": "3Skat9QtSXoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "train_metrics = trainer.train(resume_from_checkpoint=True)"
      ],
      "metadata": {
        "id": "8IS-V5-wIorg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BzDDewbAJ4M0"
      },
      "outputs": [],
      "source": [
        "print(train_metrics.metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rlk-89Gati79"
      },
      "outputs": [],
      "source": [
        "trainer.save_model(training_args.output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_kIhC1-bdCN"
      },
      "outputs": [],
      "source": [
        "trainer.save_state()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sh-JATe-beoq"
      },
      "outputs": [],
      "source": [
        "trainer.save_metrics('train', train_metrics.metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chYf46Coti4a"
      },
      "outputs": [],
      "source": [
        "raise raise Exception('Parar aqui reinício!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7OJaZ10ctUB"
      },
      "source": [
        "Teste inicio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VoBNfA_VH38_"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "train_metrics = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7oOck7ZmH1bX"
      },
      "outputs": [],
      "source": [
        "trainer = trainer_cls(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axLC5c5ecsuD"
      },
      "outputs": [],
      "source": [
        "train_metrics = trainer.train()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "hNOEKGtZ55uU",
        "cpPSgRGQ5wJv",
        "8v2gtkEPhA0t"
      ],
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "e431eb1d856c426fade2a694f8536bd46c4e9c4bd47cb4afd3fb4d2c61122b03"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0ba3379393564bd0bc348776cc9a0cd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b361732dc9b448e98a5f73dc5bb81957",
              "IPY_MODEL_8766fc68607d4cef86df608998a71ade",
              "IPY_MODEL_7273542452ea4d3198eaa3a0b5d46831"
            ],
            "layout": "IPY_MODEL_95f6db9f971c4f7bb0f722ec857215e6"
          }
        },
        "b361732dc9b448e98a5f73dc5bb81957": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7b1ef7444fd4e1998ca5909d702529b",
            "placeholder": "​",
            "style": "IPY_MODEL_cbcf6f23ea864e42acc8e4fb3b133af6",
            "value": "Tokenizing: 100%"
          }
        },
        "8766fc68607d4cef86df608998a71ade": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf4f6fbc03bb4368baae99a7c60e1711",
            "max": 282636,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d673fb1c05b9412a819e614f411d4181",
            "value": 282636
          }
        },
        "7273542452ea4d3198eaa3a0b5d46831": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0167f26ed2248b59346c4788d351f56",
            "placeholder": "​",
            "style": "IPY_MODEL_f3a1ee1f57be4e3d85a1f9720cdb2ac0",
            "value": " 282636/282636 [05:20&lt;00:00, 783.11 examples/s]"
          }
        },
        "95f6db9f971c4f7bb0f722ec857215e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "b7b1ef7444fd4e1998ca5909d702529b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbcf6f23ea864e42acc8e4fb3b133af6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf4f6fbc03bb4368baae99a7c60e1711": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d673fb1c05b9412a819e614f411d4181": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e0167f26ed2248b59346c4788d351f56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3a1ee1f57be4e3d85a1f9720cdb2ac0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}